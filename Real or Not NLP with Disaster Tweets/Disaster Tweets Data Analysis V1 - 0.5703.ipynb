{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dhsong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv('./data/train.csv', encoding='utf-8')\n",
    "raw_test = pd.read_csv('./data/test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Traits (shape, columns, missing values, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Train Data Shape** >> (7613, 5)  \n",
    "> **Test &nbsp;Data Shape** >> (3263, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 4)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Train Columns** >> [id, keyword, location, text, <U>target</U>]  \n",
    "> **Test &nbsp;Columns** >> [id, keyword, location, text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text'], dtype='object')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **keyword** & **location** has <U>missing values</U>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       26\n",
       "location    1105\n",
       "text           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. keyword**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> number of **keyword**, which has used **more than 50 times**, is **206** out of 221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oil%20spill              50\n",
       "wounds                   50\n",
       "screaming                50\n",
       "riot                     50\n",
       "wildfire                 50\n",
       "                         ..\n",
       "forest%20fire            24\n",
       "threat                   16\n",
       "inundation               14\n",
       "radiation%20emergency    14\n",
       "epicentre                13\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = pd.concat([raw_train['keyword'], raw_test['keyword']], ignore_index=True)\n",
    "keywords.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['oil%20spill', 'wounds', 'screaming', 'riot', 'wildfire',\n",
       "       'violent%20storm', 'debris', 'injuries', 'accident',\n",
       "       'buildings%20burning',\n",
       "       ...\n",
       "       'damage', 'destroy', 'rioting', 'suicide%20bombing', 'suicide%20bomb',\n",
       "       'electrocute', 'fire%20truck', 'first%20responders', 'body%20bags',\n",
       "       'evacuation'],\n",
       "      dtype='object', length=206)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_50 = keywords.value_counts()[keywords.value_counts() >= 50]\n",
    "keywords_50.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. location**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> number of **location**, which has used **more than 5 times**, is **174** out of 4521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA                          141\n",
       "New York                     109\n",
       "United States                 65\n",
       "London                        58\n",
       "Canada                        42\n",
       "                            ... \n",
       "#WashingtonState #Seattle      1\n",
       "IL                             1\n",
       "Morris, IL                     1\n",
       "Pedophilia                     1\n",
       "Newcastle upon Tyne            1\n",
       "Name: location, Length: 4521, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = pd.concat([raw_train['location'], raw_test['location']])\n",
    "locations.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USA', 'New York', 'United States', 'London', 'Canada', 'Nigeria',\n",
       "       'Worldwide', 'India', 'Los Angeles, CA', 'UK',\n",
       "       ...\n",
       "       'Germany', 'Leeds, England', 'Detroit, MI', '??', 'Austin, Texas',\n",
       "       'World Wide', 'Calgary', 'Anchorage, AK', 'Manchester, England',\n",
       "       'Asia'],\n",
       "      dtype='object', length=174)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_20 = locations.value_counts()[locations.value_counts() >= 5]\n",
    "locations_20.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(dataset):\n",
    "    dataset['text_proc'] = dataset['text'].str.strip()\n",
    "    dataset['text_proc'] = dataset['text_proc'].str.lower()\n",
    "\n",
    "    # Remove <> for labeling\n",
    "    dataset['text_proc'] = dataset['text_proc'].str.replace('[\\<\\>]', '')\n",
    "\n",
    "    # Mention labeling\n",
    "    dataset['text_proc'] = dataset['text_proc'].str.replace('@(?=[\\\\w\\\\d_]+)', ' <mention> ')\n",
    "\n",
    "    # Hashtag labeling\n",
    "    dataset['text_proc'] = dataset['text_proc'].str.replace('#(?=[\\\\w\\\\d]+)', ' <hashtag> ')\n",
    "    \n",
    "    # link labeling\n",
    "    dataset['text_proc'] = dataset['text_proc'].str.replace('[a-zA-Z]+://[a-zA-Z0-9./]+', ' <link> ')\n",
    "    \n",
    "    # remove puntuations\n",
    "    dataset['text_proc'] = dataset['text_proc'].str.replace('[^a-zA-Z\\<\\> ]+', '')\n",
    "    dataset['text_proc'] = dataset['text_proc'].str.replace('[\\\\s]+', ' ')\n",
    "    \n",
    "    # remove stopword\n",
    "    stop = stopwords.words('english')\n",
    "    dataset['text_proc'] = dataset['text_proc'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_text(raw_train)\n",
    "test = process_text(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason &lt;hashtag&gt; earthquake may allah fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive &lt;hashtag&gt; wildfires evacuation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby &lt;hashtag&gt; alaska smoke &lt;ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>two giant cranes holding bridge collapse nearb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;mention&gt; ariaahrary &lt;mention&gt; thetawniest con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>utckm volcano hawaii &lt;link&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>police investigating ebike collided car little...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>latest homes razed northern california wildfir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                              text_proc  \n",
       "0     deeds reason <hashtag> earthquake may allah fo...  \n",
       "1                 forest fire near la ronge sask canada  \n",
       "2     residents asked shelter place notified officer...  \n",
       "3     people receive <hashtag> wildfires evacuation ...  \n",
       "4     got sent photo ruby <hashtag> alaska smoke <ha...  \n",
       "...                                                 ...  \n",
       "7608  two giant cranes holding bridge collapse nearb...  \n",
       "7609  <mention> ariaahrary <mention> thetawniest con...  \n",
       "7610                        utckm volcano hawaii <link>  \n",
       "7611  police investigating ebike collided car little...  \n",
       "7612  latest homes razed northern california wildfir...  \n",
       "\n",
       "[7613 rows x 6 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>text_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>heard &lt;hashtag&gt; earthquake different cities st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>forest fire spot pond geese fleeing across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting &lt;hashtag&gt; spokane &lt;hashtag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kills china taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>earthquake safety los angeles safety fasteners...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>storm ri worse last hurricane cityampothers ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>green line derailment chicago &lt;link&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>meg issues hazardous weather outlook hwo &lt;link&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>&lt;hashtag&gt; cityofcalgary activated municipal em...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  \\\n",
       "0                    Just happened a terrible car crash   \n",
       "1     Heard about #earthquake is different cities, s...   \n",
       "2     there is a forest fire at spot pond, geese are...   \n",
       "3              Apocalypse lighting. #Spokane #wildfires   \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "...                                                 ...   \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...   \n",
       "3259  Storm in RI worse than last hurricane. My city...   \n",
       "3260  Green Line derailment in Chicago http://t.co/U...   \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...   \n",
       "3262  #CityofCalgary has activated its Municipal Eme...   \n",
       "\n",
       "                                              text_proc  \n",
       "0                           happened terrible car crash  \n",
       "1     heard <hashtag> earthquake different cities st...  \n",
       "2     forest fire spot pond geese fleeing across str...  \n",
       "3     apocalypse lighting <hashtag> spokane <hashtag...  \n",
       "4                   typhoon soudelor kills china taiwan  \n",
       "...                                                 ...  \n",
       "3258  earthquake safety los angeles safety fasteners...  \n",
       "3259  storm ri worse last hurricane cityampothers ha...  \n",
       "3260               green line derailment chicago <link>  \n",
       "3261    meg issues hazardous weather outlook hwo <link>  \n",
       "3262  <hashtag> cityofcalgary activated municipal em...  \n",
       "\n",
       "[3263 rows x 5 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique word in train 16959\n",
      "# of unique word in test 10030\n",
      "# of unique word only in tset 4420\n",
      "# of unique word 21379\n"
     ]
    }
   ],
   "source": [
    "words_train = set()\n",
    "words_test = set()\n",
    "\n",
    "for tweet in train['text_proc'].str.split():\n",
    "    for word in tweet:\n",
    "        words_train.add(word)\n",
    "for tweet in test['text_proc'].str.split():\n",
    "    for word in tweet:\n",
    "        words_test.add(word)\n",
    "\n",
    "words = words_train | words_test\n",
    "        \n",
    "print('# of unique word in train {}'.format(len(words_train)))\n",
    "print('# of unique word in test {}'.format(len(words_test)))\n",
    "print('# of unique word only in tset {}'.format(len(words_test - words_train)))\n",
    "print('# of unique word {}'.format(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokens'] = train['text_proc'].apply(lambda x: [word for word in x.split() if word in words_train])\n",
    "test['tokens'] = test['text_proc'].apply(lambda x: [word for word in x.split() if word in words_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_proc</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason &lt;hashtag&gt; earthquake may allah fo...</td>\n",
       "      <td>[deeds, reason, &lt;hashtag&gt;, earthquake, may, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive &lt;hashtag&gt; wildfires evacuation ...</td>\n",
       "      <td>[people, receive, &lt;hashtag&gt;, wildfires, evacua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby &lt;hashtag&gt; alaska smoke &lt;ha...</td>\n",
       "      <td>[got, sent, photo, ruby, &lt;hashtag&gt;, alaska, sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>two giant cranes holding bridge collapse nearb...</td>\n",
       "      <td>[two, giant, cranes, holding, bridge, collapse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;mention&gt; ariaahrary &lt;mention&gt; thetawniest con...</td>\n",
       "      <td>[&lt;mention&gt;, ariaahrary, &lt;mention&gt;, thetawniest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>utckm volcano hawaii &lt;link&gt;</td>\n",
       "      <td>[utckm, volcano, hawaii, &lt;link&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>police investigating ebike collided car little...</td>\n",
       "      <td>[police, investigating, ebike, collided, car, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>latest homes razed northern california wildfir...</td>\n",
       "      <td>[latest, homes, razed, northern, california, w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                              text_proc  \\\n",
       "0     deeds reason <hashtag> earthquake may allah fo...   \n",
       "1                 forest fire near la ronge sask canada   \n",
       "2     residents asked shelter place notified officer...   \n",
       "3     people receive <hashtag> wildfires evacuation ...   \n",
       "4     got sent photo ruby <hashtag> alaska smoke <ha...   \n",
       "...                                                 ...   \n",
       "7608  two giant cranes holding bridge collapse nearb...   \n",
       "7609  <mention> ariaahrary <mention> thetawniest con...   \n",
       "7610                        utckm volcano hawaii <link>   \n",
       "7611  police investigating ebike collided car little...   \n",
       "7612  latest homes razed northern california wildfir...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [deeds, reason, <hashtag>, earthquake, may, al...  \n",
       "1         [forest, fire, near, la, ronge, sask, canada]  \n",
       "2     [residents, asked, shelter, place, notified, o...  \n",
       "3     [people, receive, <hashtag>, wildfires, evacua...  \n",
       "4     [got, sent, photo, ruby, <hashtag>, alaska, sm...  \n",
       "...                                                 ...  \n",
       "7608  [two, giant, cranes, holding, bridge, collapse...  \n",
       "7609  [<mention>, ariaahrary, <mention>, thetawniest...  \n",
       "7610                   [utckm, volcano, hawaii, <link>]  \n",
       "7611  [police, investigating, ebike, collided, car, ...  \n",
       "7612  [latest, homes, razed, northern, california, w...  \n",
       "\n",
       "[7613 rows x 7 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>text_proc</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>[happened, terrible, car, crash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>heard &lt;hashtag&gt; earthquake different cities st...</td>\n",
       "      <td>[heard, &lt;hashtag&gt;, earthquake, different, citi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>forest fire spot pond geese fleeing across str...</td>\n",
       "      <td>[forest, fire, spot, pond, fleeing, across, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting &lt;hashtag&gt; spokane &lt;hashtag...</td>\n",
       "      <td>[apocalypse, lighting, &lt;hashtag&gt;, spokane, &lt;ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kills china taiwan</td>\n",
       "      <td>[typhoon, soudelor, kills, china, taiwan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>earthquake safety los angeles safety fasteners...</td>\n",
       "      <td>[earthquake, safety, los, angeles, safety]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>storm ri worse last hurricane cityampothers ha...</td>\n",
       "      <td>[storm, ri, worse, last, hurricane, cityampoth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>green line derailment chicago &lt;link&gt;</td>\n",
       "      <td>[green, line, derailment, chicago, &lt;link&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>meg issues hazardous weather outlook hwo &lt;link&gt;</td>\n",
       "      <td>[meg, issues, hazardous, weather, outlook, hwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>&lt;hashtag&gt; cityofcalgary activated municipal em...</td>\n",
       "      <td>[&lt;hashtag&gt;, cityofcalgary, activated, municipa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  \\\n",
       "0                    Just happened a terrible car crash   \n",
       "1     Heard about #earthquake is different cities, s...   \n",
       "2     there is a forest fire at spot pond, geese are...   \n",
       "3              Apocalypse lighting. #Spokane #wildfires   \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "...                                                 ...   \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...   \n",
       "3259  Storm in RI worse than last hurricane. My city...   \n",
       "3260  Green Line derailment in Chicago http://t.co/U...   \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...   \n",
       "3262  #CityofCalgary has activated its Municipal Eme...   \n",
       "\n",
       "                                              text_proc  \\\n",
       "0                           happened terrible car crash   \n",
       "1     heard <hashtag> earthquake different cities st...   \n",
       "2     forest fire spot pond geese fleeing across str...   \n",
       "3     apocalypse lighting <hashtag> spokane <hashtag...   \n",
       "4                   typhoon soudelor kills china taiwan   \n",
       "...                                                 ...   \n",
       "3258  earthquake safety los angeles safety fasteners...   \n",
       "3259  storm ri worse last hurricane cityampothers ha...   \n",
       "3260               green line derailment chicago <link>   \n",
       "3261    meg issues hazardous weather outlook hwo <link>   \n",
       "3262  <hashtag> cityofcalgary activated municipal em...   \n",
       "\n",
       "                                                 tokens  \n",
       "0                      [happened, terrible, car, crash]  \n",
       "1     [heard, <hashtag>, earthquake, different, citi...  \n",
       "2     [forest, fire, spot, pond, fleeing, across, st...  \n",
       "3     [apocalypse, lighting, <hashtag>, spokane, <ha...  \n",
       "4             [typhoon, soudelor, kills, china, taiwan]  \n",
       "...                                                 ...  \n",
       "3258         [earthquake, safety, los, angeles, safety]  \n",
       "3259  [storm, ri, worse, last, hurricane, cityampoth...  \n",
       "3260         [green, line, derailment, chicago, <link>]  \n",
       "3261  [meg, issues, hazardous, weather, outlook, hwo...  \n",
       "3262  [<hashtag>, cityofcalgary, activated, municipa...  \n",
       "\n",
       "[3263 rows x 6 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = train['tokens']\n",
    "y_train_target = train['target']\n",
    "x_test_tokens = test['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263,)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<hashtag>',\n",
       " '<link>',\n",
       " '<mention>',\n",
       " 'aa',\n",
       " 'aaaa',\n",
       " 'aaaaaaallll',\n",
       " 'aaarrrgghhh',\n",
       " 'aaceorg',\n",
       " 'aal',\n",
       " 'aampb',\n",
       " 'aampw',\n",
       " 'aan',\n",
       " 'aannnnd',\n",
       " 'aar',\n",
       " 'aaronthefm',\n",
       " 'aashiqui',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandonedpics',\n",
       " 'abandoning',\n",
       " 'abbandoned',\n",
       " 'abbott',\n",
       " 'abbruchsimulator',\n",
       " 'abbswinston',\n",
       " 'abbyairshow',\n",
       " 'abc',\n",
       " 'abcchicago',\n",
       " 'abceyewitness',\n",
       " 'abcnews',\n",
       " 'abcnorio',\n",
       " 'abcs',\n",
       " 'abe',\n",
       " 'aberdeen',\n",
       " 'aberdeenfanpage',\n",
       " 'aberdeenfc',\n",
       " 'aberystwythshrewsbury',\n",
       " 'abes',\n",
       " 'abetter',\n",
       " 'abha',\n",
       " 'abia',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'ableg',\n",
       " 'abninfvet',\n",
       " 'aboard',\n",
       " 'abomb',\n",
       " 'abombed',\n",
       " 'abomination',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abouts',\n",
       " 'abovewould',\n",
       " 'abrancaballero',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutsumya',\n",
       " 'abstorm',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdly',\n",
       " 'abubaraa',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuseddesolateamplost',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abysmaljoiner',\n",
       " 'ac',\n",
       " 'acaciapenn',\n",
       " 'academia',\n",
       " 'acarewornheart',\n",
       " 'acc',\n",
       " 'accept',\n",
       " 'accepte',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accidentalprophecy',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'accidentwho',\n",
       " 'accionempresa',\n",
       " 'accompanying',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accountable',\n",
       " 'accounts',\n",
       " 'accuracy',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accustomed',\n",
       " 'acdcd',\n",
       " 'acdelco',\n",
       " 'ace',\n",
       " 'acebabes',\n",
       " 'acebreakingnews',\n",
       " 'acee',\n",
       " 'acenewsdesk',\n",
       " 'acesse',\n",
       " 'achedin',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'achieving',\n",
       " 'achimota',\n",
       " 'aching',\n",
       " 'acid',\n",
       " 'acids',\n",
       " 'acmilan',\n",
       " 'acne',\n",
       " 'acoustic',\n",
       " 'acousticmaloley',\n",
       " 'acquiesce',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquisitions',\n",
       " 'acres',\n",
       " 'acronym',\n",
       " 'across',\n",
       " 'acrylic',\n",
       " 'act',\n",
       " 'actavis',\n",
       " 'acted',\n",
       " 'actin',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actionmoviestaughtus',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activision',\n",
       " 'activist',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'acura',\n",
       " 'acute',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adamantly',\n",
       " 'adamnibloe',\n",
       " 'adamrubinespn',\n",
       " 'adamtuss',\n",
       " 'adani',\n",
       " 'adanne',\n",
       " 'adaptation',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'address',\n",
       " 'addresses',\n",
       " 'addtexastonextdtour',\n",
       " 'adelaide',\n",
       " 'adhd',\n",
       " 'adidas',\n",
       " 'adiossuperbacterias',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjuster',\n",
       " 'admin',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'adndotcom',\n",
       " 'adopt',\n",
       " 'adoption',\n",
       " 'adoptive',\n",
       " 'adorable',\n",
       " 'adorableappple',\n",
       " 'adrianpeel',\n",
       " 'adriasimon',\n",
       " 'adriennetomah',\n",
       " 'ads',\n",
       " 'adsit',\n",
       " 'adult',\n",
       " 'adultblackmale',\n",
       " 'adults',\n",
       " 'adumbbb',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advantages',\n",
       " 'adventures',\n",
       " 'adverse',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advice',\n",
       " 'advised',\n",
       " 'advisory',\n",
       " 'adweek',\n",
       " 'aeg',\n",
       " 'aelinrhee',\n",
       " 'aeroplane',\n",
       " 'aerospace',\n",
       " 'aesthetic',\n",
       " 'af',\n",
       " 'afc',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'affiliate',\n",
       " 'affiliation',\n",
       " 'afflecki',\n",
       " 'affliction',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'afghetcleft',\n",
       " 'afk',\n",
       " 'afloat',\n",
       " 'afp',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africanbaze',\n",
       " 'africans',\n",
       " 'africansinsf',\n",
       " 'africas',\n",
       " 'afrikaan',\n",
       " 'afrin',\n",
       " 'afte',\n",
       " 'afterhaiyan',\n",
       " 'afterhours',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'aftershock',\n",
       " 'aftershockdelo',\n",
       " 'aftershockorg',\n",
       " 'aftershocks',\n",
       " 'afterwards',\n",
       " 'afycso',\n",
       " 'ag',\n",
       " 'agalloch',\n",
       " 'agdq',\n",
       " 'age',\n",
       " 'ageekyfangirl',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggarwal',\n",
       " 'aggressif',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'agnivesh',\n",
       " 'agnus',\n",
       " 'ago',\n",
       " 'agochicago',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreements',\n",
       " 'agrees',\n",
       " 'agreeshe',\n",
       " 'agthanover',\n",
       " 'agtparis',\n",
       " 'aguero',\n",
       " 'agusa',\n",
       " 'agw',\n",
       " 'ah',\n",
       " 'ahahahga',\n",
       " 'ahamedis',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'ahhtheenikki',\n",
       " 'ahmazing',\n",
       " 'ahrar',\n",
       " 'ahuh',\n",
       " 'aias',\n",
       " 'aiclimate',\n",
       " 'aid',\n",
       " 'aidade',\n",
       " 'aidan',\n",
       " 'aids',\n",
       " 'aiginsurance',\n",
       " 'aiiamericangiri',\n",
       " 'aiii',\n",
       " 'aim',\n",
       " 'aimlessly',\n",
       " 'aint',\n",
       " 'aintsheperty',\n",
       " 'air',\n",
       " 'airasia',\n",
       " 'airbullet',\n",
       " 'aircraft',\n",
       " 'airhead',\n",
       " 'airhorns',\n",
       " 'airi',\n",
       " 'airing',\n",
       " 'airlift',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airstrikes',\n",
       " 'airwaves',\n",
       " 'aisle',\n",
       " 'aisumage',\n",
       " 'aitchkaycee',\n",
       " 'ajabrown',\n",
       " 'ajw',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akame',\n",
       " 'akarb',\n",
       " 'akcsl',\n",
       " 'akgovbillwalker',\n",
       " 'akilah',\n",
       " 'akito',\n",
       " 'akrams',\n",
       " 'aks',\n",
       " 'akumareisu',\n",
       " 'akwa',\n",
       " 'akx',\n",
       " 'akxbskdn',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alabamaquake',\n",
       " 'aladdin',\n",
       " 'alameda',\n",
       " 'alamodc',\n",
       " 'alanhahn',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarmems',\n",
       " 'alarming',\n",
       " 'alarmingly',\n",
       " 'alarms',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'alaskan',\n",
       " 'alaskas',\n",
       " 'alaskaseafood',\n",
       " 'alba',\n",
       " 'albany',\n",
       " 'albeit',\n",
       " 'alberta',\n",
       " 'albertans',\n",
       " 'albertas',\n",
       " 'albertsons',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alchemist',\n",
       " 'alcohol',\n",
       " 'alcoholandmetal',\n",
       " 'alcoholismaddiction',\n",
       " 'aldridge',\n",
       " 'alec',\n",
       " 'aleisstokes',\n",
       " 'alekalicante',\n",
       " 'alert',\n",
       " 'alerts',\n",
       " 'alex',\n",
       " 'alexalltimelow',\n",
       " 'alexandrapullin',\n",
       " 'alexandrian',\n",
       " 'alexbelloli',\n",
       " 'alexeivolkov',\n",
       " 'alexhammerstone',\n",
       " 'alexis',\n",
       " 'alexissanchez',\n",
       " 'alexjacobsonpfs',\n",
       " 'alexshipppp',\n",
       " 'alextucker',\n",
       " 'alfapedia',\n",
       " 'algae',\n",
       " 'algeria',\n",
       " 'alhaji',\n",
       " 'alhanda',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'aliens',\n",
       " 'alifaditha',\n",
       " 'align',\n",
       " 'alil',\n",
       " 'alipaper',\n",
       " 'alisonannyoung',\n",
       " 'alive',\n",
       " 'aliveafter',\n",
       " 'alivebut',\n",
       " 'allah',\n",
       " 'allahsfinest',\n",
       " 'allay',\n",
       " 'alldaycumshots',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allenenbot',\n",
       " 'allergic',\n",
       " 'alley',\n",
       " 'alliance',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'allin',\n",
       " 'allinwithchris',\n",
       " 'alllivesmatter',\n",
       " 'alllll',\n",
       " 'allocating',\n",
       " 'alloosh',\n",
       " 'allotment',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alloy',\n",
       " 'allpro',\n",
       " 'allthekidneybeansandsorbetmisha',\n",
       " 'allthenews',\n",
       " 'alltime',\n",
       " 'ally',\n",
       " 'allyinwondrland',\n",
       " 'almighty',\n",
       " 'almost',\n",
       " 'almusafirah',\n",
       " 'alois',\n",
       " 'alone',\n",
       " 'alonedont',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'alphen',\n",
       " 'alps',\n",
       " 'alrasyiditurasya',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'alrightbut',\n",
       " 'alrighty',\n",
       " 'alska',\n",
       " 'also',\n",
       " 'alsowhat',\n",
       " 'alt',\n",
       " 'altamonte',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'alton',\n",
       " 'aluminum',\n",
       " 'alves',\n",
       " 'alvinnelson',\n",
       " 'always',\n",
       " 'alwsl',\n",
       " 'alwx',\n",
       " 'ama',\n",
       " 'amageddon',\n",
       " 'amalie',\n",
       " 'amaramin',\n",
       " 'amateur',\n",
       " 'amateurnester',\n",
       " 'amazed',\n",
       " 'amazin',\n",
       " 'amazing',\n",
       " 'amazingness',\n",
       " 'amazon',\n",
       " 'amazondeals',\n",
       " 'amazons',\n",
       " 'amber',\n",
       " 'ambition',\n",
       " 'ambleside',\n",
       " 'ambulance',\n",
       " 'ambulances',\n",
       " 'ambulancewe',\n",
       " 'amcx',\n",
       " 'amdollela',\n",
       " 'ameenshaikh',\n",
       " 'amen',\n",
       " 'amends',\n",
       " 'ameribag',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanlegion',\n",
       " 'americans',\n",
       " 'americas',\n",
       " 'americayour',\n",
       " 'ames',\n",
       " 'amesocialaction',\n",
       " 'amicos',\n",
       " 'amicospizzato',\n",
       " 'amid',\n",
       " 'amiddleaged',\n",
       " 'amiibos',\n",
       " 'aminakh',\n",
       " 'aminespn',\n",
       " 'amino',\n",
       " 'amirite',\n",
       " 'amirkingkhan',\n",
       " 'amman',\n",
       " 'amo',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amp',\n",
       " 'ampamp',\n",
       " 'ampask',\n",
       " 'ampgot',\n",
       " 'amplifier',\n",
       " 'ampmdash',\n",
       " 'ampor',\n",
       " 'ampstart',\n",
       " 'ampstory',\n",
       " 'ampwanted',\n",
       " 'amreading',\n",
       " 'amritsarthats',\n",
       " 'amsal',\n",
       " 'amssummer',\n",
       " 'amsterdam',\n",
       " 'amumumux',\n",
       " 'amznfavorites',\n",
       " 'ana',\n",
       " 'anakin',\n",
       " 'analog',\n",
       " 'analysis',\n",
       " 'anarchicteapot',\n",
       " 'anarchy',\n",
       " 'anathemazhiv',\n",
       " 'anatomy',\n",
       " 'anchor',\n",
       " 'anchorage',\n",
       " 'anchors',\n",
       " 'ancient',\n",
       " 'ancop',\n",
       " 'andchina',\n",
       " 'anders',\n",
       " 'anderson',\n",
       " 'andor',\n",
       " 'andre',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'androidgames',\n",
       " 'ands',\n",
       " 'andy',\n",
       " 'andygilder',\n",
       " 'anellatulip',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelheartnight',\n",
       " 'angelina',\n",
       " 'angelriveralib',\n",
       " 'angels',\n",
       " 'angelstar',\n",
       " 'anger',\n",
       " 'angers',\n",
       " 'angharadjames',\n",
       " 'angioplasty',\n",
       " 'angry',\n",
       " 'angusmacneilsnp',\n",
       " 'anhqdc',\n",
       " 'ani',\n",
       " 'animal',\n",
       " 'animaladvocate',\n",
       " 'animallogic',\n",
       " 'animalrescue',\n",
       " 'animals',\n",
       " 'animations',\n",
       " 'animatronics',\n",
       " 'anime',\n",
       " 'aniston',\n",
       " 'anjem',\n",
       " 'ankle',\n",
       " 'ankles',\n",
       " 'anna',\n",
       " 'annaciclismo',\n",
       " 'annajhm',\n",
       " 'annddd',\n",
       " 'annealiz',\n",
       " 'annihilate',\n",
       " 'annihilated',\n",
       " 'annihilating',\n",
       " 'annihilation',\n",
       " 'anniversary',\n",
       " 'annmarieronan',\n",
       " 'annonymous',\n",
       " 'annoucement',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'anonchimp',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answers',\n",
       " 'answersplus',\n",
       " 'ant',\n",
       " 'ante',\n",
       " 'anthelmintic',\n",
       " 'anthology',\n",
       " 'anthony',\n",
       " 'anthonys',\n",
       " 'anthrax',\n",
       " 'anthxvy',\n",
       " 'anti',\n",
       " 'antiblight',\n",
       " 'antichrist',\n",
       " 'antifeminist',\n",
       " 'antioch',\n",
       " 'antiochhickoryhollow',\n",
       " 'antiochus',\n",
       " 'antiterrorism',\n",
       " 'antonio',\n",
       " 'antony',\n",
       " 'antpips',\n",
       " 'ants',\n",
       " 'anu',\n",
       " 'anumber',\n",
       " 'anxiety',\n",
       " 'anxietyproblems',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anymorethats',\n",
       " 'anyone',\n",
       " 'anyoneor',\n",
       " 'anything',\n",
       " 'anythingthere',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'anza',\n",
       " 'aogashima',\n",
       " 'aoms',\n",
       " 'ap',\n",
       " 'apano',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apartments',\n",
       " 'apaz',\n",
       " 'apc',\n",
       " 'apch',\n",
       " 'apcpdp',\n",
       " 'apd',\n",
       " 'apga',\n",
       " 'aphiabeta',\n",
       " 'aphl',\n",
       " 'aphyr',\n",
       " 'apiece',\n",
       " 'apocalpytic',\n",
       " 'apocalypse',\n",
       " 'apocalypsetunein',\n",
       " 'apocalyptic',\n",
       " 'apollo',\n",
       " 'apollobrown',\n",
       " 'apollobrowns',\n",
       " 'apologies',\n",
       " 'apologise',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'app',\n",
       " 'appalling',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeals',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'apperception',\n",
       " 'appetite',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'appleofficlal',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appointment',\n",
       " 'appoints',\n",
       " 'appraisal',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciativeinquiry',\n",
       " 'approach',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriation',\n",
       " 'approval',\n",
       " 'approves',\n",
       " 'appx',\n",
       " 'appys',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'apropos',\n",
       " 'apt',\n",
       " 'aptlyengineerd',\n",
       " 'apts',\n",
       " 'aqua',\n",
       " 'aquarium',\n",
       " 'aquarius',\n",
       " 'ar',\n",
       " 'ara',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arabian',\n",
       " 'arabic',\n",
       " 'arachys',\n",
       " 'arcade',\n",
       " 'arceen',\n",
       " 'archetype',\n",
       " 'archipelagowolves',\n",
       " 'architect',\n",
       " 'architects',\n",
       " 'architecture',\n",
       " 'area',\n",
       " 'areal',\n",
       " 'areas',\n",
       " 'areasminor',\n",
       " 'areavoluntaryinciwebmad',\n",
       " 'areawctv',\n",
       " 'aredeluged',\n",
       " 'arena',\n",
       " 'arenanone',\n",
       " 'arent',\n",
       " 'areva',\n",
       " 'arfur',\n",
       " 'argentaelite',\n",
       " 'argentina',\n",
       " 'argentinean',\n",
       " 'argentings',\n",
       " 'argh',\n",
       " 'argsuppose',\n",
       " 'argue',\n",
       " 'argues',\n",
       " 'argument',\n",
       " 'argus',\n",
       " 'ari',\n",
       " 'ariaahrary',\n",
       " 'ariabrisard',\n",
       " 'arian',\n",
       " 'ariana',\n",
       " 'arianagrande',\n",
       " 'arianareed',\n",
       " 'arin',\n",
       " 'aris',\n",
       " 'ariz',\n",
       " 'arizona',\n",
       " 'arizonadot',\n",
       " 'arizzo',\n",
       " 'arkan',\n",
       " 'arkansas',\n",
       " 'arlington',\n",
       " 'arm',\n",
       " 'armageddon',\n",
       " 'armed',\n",
       " 'armenians',\n",
       " 'armory',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'armys',\n",
       " 'arnhem',\n",
       " 'arobotlegion',\n",
       " 'around',\n",
       " 'aroundthe',\n",
       " 'aroundyoull',\n",
       " 'arovolturi',\n",
       " 'arranged',\n",
       " 'arreat',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arrestpastornganga',\n",
       " 'arrests',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogant',\n",
       " 'ars',\n",
       " 'arse',\n",
       " 'arsenal',\n",
       " 'arsenals',\n",
       " 'arson',\n",
       " 'arsonattack',\n",
       " 'arsonist',\n",
       " 'arsonistmusic',\n",
       " 'arsonists',\n",
       " 'art',\n",
       " 'artbrut',\n",
       " 'artectura',\n",
       " 'arti',\n",
       " 'articals',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'artificial',\n",
       " 'artillery',\n",
       " 'artist',\n",
       " 'artisteoftheweekfact',\n",
       " 'artists',\n",
       " 'artistsunited',\n",
       " 'arts',\n",
       " 'artwork',\n",
       " 'arvindkejriwal',\n",
       " 'arwx',\n",
       " 'ary',\n",
       " 'asae',\n",
       " 'asap',\n",
       " 'asapalsowatches',\n",
       " 'asb',\n",
       " 'asbury',\n",
       " 'asburyparkpress',\n",
       " 'ascend',\n",
       " 'aseer',\n",
       " 'asf',\n",
       " 'ash',\n",
       " 'ashayo',\n",
       " 'ashberxo',\n",
       " 'ashdod',\n",
       " 'ashenforest',\n",
       " 'ashes',\n",
       " 'ashesashes',\n",
       " 'ashestoashes',\n",
       " 'ashghebranious',\n",
       " 'ashj',\n",
       " 'ashley',\n",
       " 'ashrafiyah',\n",
       " 'ashtonsos',\n",
       " 'ashville',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asianshawtyy',\n",
       " 'asics',\n",
       " 'aside',\n",
       " 'asimtanvir',\n",
       " 'ask',\n",
       " 'askcharley',\n",
       " 'askconnor',\n",
       " 'asked',\n",
       " 'askforalaska',\n",
       " 'askhcz',\n",
       " 'askin',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'asphalt',\n",
       " 'aspiring',\n",
       " 'ass',\n",
       " 'assad',\n",
       " 'assailant',\n",
       " 'assassinkpg',\n",
       " 'assassins',\n",
       " 'assault',\n",
       " 'assembly',\n",
       " 'assertative',\n",
       " 'asses',\n",
       " 'assessment',\n",
       " 'assets',\n",
       " 'asshole',\n",
       " 'assholes',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assisting',\n",
       " 'assnchat',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assumes',\n",
       " 'assured',\n",
       " 'asswipe',\n",
       " 'asterpuppet',\n",
       " 'astonishing',\n",
       " 'astounding',\n",
       " 'astrakhan',\n",
       " 'astrologian',\n",
       " 'astrology',\n",
       " 'astros',\n",
       " 'astroturfers',\n",
       " 'asukager',\n",
       " 'asylum',\n",
       " 'asymbina',\n",
       " 'atamathon',\n",
       " 'atc',\n",
       " 'atcha',\n",
       " 'atchisonsean',\n",
       " 'atcinema',\n",
       " 'ate',\n",
       " 'atgrannyshouse',\n",
       " 'atheistic',\n",
       " 'athens',\n",
       " 'athlete',\n",
       " 'athletics',\n",
       " 'atk',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atlarnxx',\n",
       " 'atlas',\n",
       " 'atlbizchron',\n",
       " 'atleast',\n",
       " 'atlevents',\n",
       " 'atljw',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atom',\n",
       " 'atombomb',\n",
       " 'atomic',\n",
       " 'atomicbomb',\n",
       " 'att',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attackclose',\n",
       " 'attacked',\n",
       " 'attacking',\n",
       " 'attackonstiles',\n",
       " 'attacks',\n",
       " 'attackshare',\n",
       " 'attained',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attendance',\n",
       " 'attended',\n",
       " 'attendees',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attic',\n",
       " 'attila',\n",
       " 'attitude',\n",
       " 'attjcdemos',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'atv',\n",
       " 'au',\n",
       " 'aubilenon',\n",
       " 'aubrey',\n",
       " 'auburn',\n",
       " 'auc',\n",
       " 'auckland',\n",
       " 'auction',\n",
       " 'auctions',\n",
       " 'audaciousspunk',\n",
       " 'audacityjamesta',\n",
       " 'audi',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'audio',\n",
       " 'audit',\n",
       " 'audreyp',\n",
       " 'aug',\n",
       " 'august',\n",
       " 'aul',\n",
       " 'aunt',\n",
       " 'auntiedote',\n",
       " 'aurora',\n",
       " 'aus',\n",
       " 'ausinstarchitect',\n",
       " 'auspol',\n",
       " 'aussie',\n",
       " 'aussies',\n",
       " 'aust',\n",
       " 'austin',\n",
       " 'austinpearcy',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'australians',\n",
       " 'australias',\n",
       " 'austrian',\n",
       " 'auth',\n",
       " 'authentic',\n",
       " 'authenticating',\n",
       " 'author',\n",
       " 'authorities',\n",
       " 'authormike',\n",
       " ...]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = ['<pad>'] + sorted(words_train)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: '<pad>',\n",
       " 1: '<hashtag>',\n",
       " 2: '<link>',\n",
       " 3: '<mention>',\n",
       " 4: 'aa',\n",
       " 5: 'aaaa',\n",
       " 6: 'aaaaaaallll',\n",
       " 7: 'aaarrrgghhh',\n",
       " 8: 'aaceorg',\n",
       " 9: 'aal',\n",
       " 10: 'aampb',\n",
       " 11: 'aampw',\n",
       " 12: 'aan',\n",
       " 13: 'aannnnd',\n",
       " 14: 'aar',\n",
       " 15: 'aaronthefm',\n",
       " 16: 'aashiqui',\n",
       " 17: 'ab',\n",
       " 18: 'aba',\n",
       " 19: 'abandon',\n",
       " 20: 'abandoned',\n",
       " 21: 'abandonedpics',\n",
       " 22: 'abandoning',\n",
       " 23: 'abbandoned',\n",
       " 24: 'abbott',\n",
       " 25: 'abbruchsimulator',\n",
       " 26: 'abbswinston',\n",
       " 27: 'abbyairshow',\n",
       " 28: 'abc',\n",
       " 29: 'abcchicago',\n",
       " 30: 'abceyewitness',\n",
       " 31: 'abcnews',\n",
       " 32: 'abcnorio',\n",
       " 33: 'abcs',\n",
       " 34: 'abe',\n",
       " 35: 'aberdeen',\n",
       " 36: 'aberdeenfanpage',\n",
       " 37: 'aberdeenfc',\n",
       " 38: 'aberystwythshrewsbury',\n",
       " 39: 'abes',\n",
       " 40: 'abetter',\n",
       " 41: 'abha',\n",
       " 42: 'abia',\n",
       " 43: 'ability',\n",
       " 44: 'abject',\n",
       " 45: 'ablaze',\n",
       " 46: 'able',\n",
       " 47: 'ableg',\n",
       " 48: 'abninfvet',\n",
       " 49: 'aboard',\n",
       " 50: 'abomb',\n",
       " 51: 'abombed',\n",
       " 52: 'abomination',\n",
       " 53: 'abortion',\n",
       " 54: 'abortions',\n",
       " 55: 'abouts',\n",
       " 56: 'abovewould',\n",
       " 57: 'abrancaballero',\n",
       " 58: 'abs',\n",
       " 59: 'absence',\n",
       " 60: 'absolute',\n",
       " 61: 'absolutely',\n",
       " 62: 'absolutsumya',\n",
       " 63: 'abstorm',\n",
       " 64: 'abstract',\n",
       " 65: 'absurd',\n",
       " 66: 'absurdly',\n",
       " 67: 'abubaraa',\n",
       " 68: 'abuse',\n",
       " 69: 'abused',\n",
       " 70: 'abuseddesolateamplost',\n",
       " 71: 'abuses',\n",
       " 72: 'abusing',\n",
       " 73: 'abysmaljoiner',\n",
       " 74: 'ac',\n",
       " 75: 'acaciapenn',\n",
       " 76: 'academia',\n",
       " 77: 'acarewornheart',\n",
       " 78: 'acc',\n",
       " 79: 'accept',\n",
       " 80: 'accepte',\n",
       " 81: 'accepts',\n",
       " 82: 'access',\n",
       " 83: 'accident',\n",
       " 84: 'accidentally',\n",
       " 85: 'accidentalprophecy',\n",
       " 86: 'accidently',\n",
       " 87: 'accidents',\n",
       " 88: 'accidentwho',\n",
       " 89: 'accionempresa',\n",
       " 90: 'accompanying',\n",
       " 91: 'according',\n",
       " 92: 'accordingly',\n",
       " 93: 'account',\n",
       " 94: 'accountable',\n",
       " 95: 'accounts',\n",
       " 96: 'accuracy',\n",
       " 97: 'accused',\n",
       " 98: 'accuses',\n",
       " 99: 'accustomed',\n",
       " 100: 'acdcd',\n",
       " 101: 'acdelco',\n",
       " 102: 'ace',\n",
       " 103: 'acebabes',\n",
       " 104: 'acebreakingnews',\n",
       " 105: 'acee',\n",
       " 106: 'acenewsdesk',\n",
       " 107: 'acesse',\n",
       " 108: 'achedin',\n",
       " 109: 'achieve',\n",
       " 110: 'achievement',\n",
       " 111: 'achieving',\n",
       " 112: 'achimota',\n",
       " 113: 'aching',\n",
       " 114: 'acid',\n",
       " 115: 'acids',\n",
       " 116: 'acmilan',\n",
       " 117: 'acne',\n",
       " 118: 'acoustic',\n",
       " 119: 'acousticmaloley',\n",
       " 120: 'acquiesce',\n",
       " 121: 'acquire',\n",
       " 122: 'acquired',\n",
       " 123: 'acquisitions',\n",
       " 124: 'acres',\n",
       " 125: 'acronym',\n",
       " 126: 'across',\n",
       " 127: 'acrylic',\n",
       " 128: 'act',\n",
       " 129: 'actavis',\n",
       " 130: 'acted',\n",
       " 131: 'actin',\n",
       " 132: 'acting',\n",
       " 133: 'action',\n",
       " 134: 'actionmoviestaughtus',\n",
       " 135: 'actions',\n",
       " 136: 'activate',\n",
       " 137: 'activated',\n",
       " 138: 'activates',\n",
       " 139: 'active',\n",
       " 140: 'actively',\n",
       " 141: 'activision',\n",
       " 142: 'activist',\n",
       " 143: 'activities',\n",
       " 144: 'activity',\n",
       " 145: 'actor',\n",
       " 146: 'actress',\n",
       " 147: 'acts',\n",
       " 148: 'actual',\n",
       " 149: 'actually',\n",
       " 150: 'acura',\n",
       " 151: 'acute',\n",
       " 152: 'ad',\n",
       " 153: 'adam',\n",
       " 154: 'adamantly',\n",
       " 155: 'adamnibloe',\n",
       " 156: 'adamrubinespn',\n",
       " 157: 'adamtuss',\n",
       " 158: 'adani',\n",
       " 159: 'adanne',\n",
       " 160: 'adaptation',\n",
       " 161: 'add',\n",
       " 162: 'added',\n",
       " 163: 'addict',\n",
       " 164: 'addiction',\n",
       " 165: 'addicts',\n",
       " 166: 'adding',\n",
       " 167: 'addition',\n",
       " 168: 'address',\n",
       " 169: 'addresses',\n",
       " 170: 'addtexastonextdtour',\n",
       " 171: 'adelaide',\n",
       " 172: 'adhd',\n",
       " 173: 'adidas',\n",
       " 174: 'adiossuperbacterias',\n",
       " 175: 'adjust',\n",
       " 176: 'adjustable',\n",
       " 177: 'adjuster',\n",
       " 178: 'admin',\n",
       " 179: 'administration',\n",
       " 180: 'administrative',\n",
       " 181: 'admit',\n",
       " 182: 'admits',\n",
       " 183: 'adndotcom',\n",
       " 184: 'adopt',\n",
       " 185: 'adoption',\n",
       " 186: 'adoptive',\n",
       " 187: 'adorable',\n",
       " 188: 'adorableappple',\n",
       " 189: 'adrianpeel',\n",
       " 190: 'adriasimon',\n",
       " 191: 'adriennetomah',\n",
       " 192: 'ads',\n",
       " 193: 'adsit',\n",
       " 194: 'adult',\n",
       " 195: 'adultblackmale',\n",
       " 196: 'adults',\n",
       " 197: 'adumbbb',\n",
       " 198: 'advance',\n",
       " 199: 'advanced',\n",
       " 200: 'advances',\n",
       " 201: 'advantages',\n",
       " 202: 'adventures',\n",
       " 203: 'adverse',\n",
       " 204: 'advertise',\n",
       " 205: 'advertised',\n",
       " 206: 'advice',\n",
       " 207: 'advised',\n",
       " 208: 'advisory',\n",
       " 209: 'adweek',\n",
       " 210: 'aeg',\n",
       " 211: 'aelinrhee',\n",
       " 212: 'aeroplane',\n",
       " 213: 'aerospace',\n",
       " 214: 'aesthetic',\n",
       " 215: 'af',\n",
       " 216: 'afc',\n",
       " 217: 'affair',\n",
       " 218: 'affect',\n",
       " 219: 'affected',\n",
       " 220: 'affecting',\n",
       " 221: 'affects',\n",
       " 222: 'affiliate',\n",
       " 223: 'affiliation',\n",
       " 224: 'afflecki',\n",
       " 225: 'affliction',\n",
       " 226: 'afghan',\n",
       " 227: 'afghanistan',\n",
       " 228: 'afghetcleft',\n",
       " 229: 'afk',\n",
       " 230: 'afloat',\n",
       " 231: 'afp',\n",
       " 232: 'afraid',\n",
       " 233: 'africa',\n",
       " 234: 'african',\n",
       " 235: 'africanbaze',\n",
       " 236: 'africans',\n",
       " 237: 'africansinsf',\n",
       " 238: 'africas',\n",
       " 239: 'afrikaan',\n",
       " 240: 'afrin',\n",
       " 241: 'afte',\n",
       " 242: 'afterhaiyan',\n",
       " 243: 'afterhours',\n",
       " 244: 'afterlife',\n",
       " 245: 'aftermath',\n",
       " 246: 'afternoon',\n",
       " 247: 'aftershock',\n",
       " 248: 'aftershockdelo',\n",
       " 249: 'aftershockorg',\n",
       " 250: 'aftershocks',\n",
       " 251: 'afterwards',\n",
       " 252: 'afycso',\n",
       " 253: 'ag',\n",
       " 254: 'agalloch',\n",
       " 255: 'agdq',\n",
       " 256: 'age',\n",
       " 257: 'ageekyfangirl',\n",
       " 258: 'agencies',\n",
       " 259: 'agency',\n",
       " 260: 'agent',\n",
       " 261: 'agents',\n",
       " 262: 'ages',\n",
       " 263: 'aggarwal',\n",
       " 264: 'aggressif',\n",
       " 265: 'aggression',\n",
       " 266: 'aggressive',\n",
       " 267: 'aggressively',\n",
       " 268: 'agnivesh',\n",
       " 269: 'agnus',\n",
       " 270: 'ago',\n",
       " 271: 'agochicago',\n",
       " 272: 'agony',\n",
       " 273: 'agree',\n",
       " 274: 'agreed',\n",
       " 275: 'agreements',\n",
       " 276: 'agrees',\n",
       " 277: 'agreeshe',\n",
       " 278: 'agthanover',\n",
       " 279: 'agtparis',\n",
       " 280: 'aguero',\n",
       " 281: 'agusa',\n",
       " 282: 'agw',\n",
       " 283: 'ah',\n",
       " 284: 'ahahahga',\n",
       " 285: 'ahamedis',\n",
       " 286: 'ahead',\n",
       " 287: 'ahh',\n",
       " 288: 'ahhhh',\n",
       " 289: 'ahhhhh',\n",
       " 290: 'ahhtheenikki',\n",
       " 291: 'ahmazing',\n",
       " 292: 'ahrar',\n",
       " 293: 'ahuh',\n",
       " 294: 'aias',\n",
       " 295: 'aiclimate',\n",
       " 296: 'aid',\n",
       " 297: 'aidade',\n",
       " 298: 'aidan',\n",
       " 299: 'aids',\n",
       " 300: 'aiginsurance',\n",
       " 301: 'aiiamericangiri',\n",
       " 302: 'aiii',\n",
       " 303: 'aim',\n",
       " 304: 'aimlessly',\n",
       " 305: 'aint',\n",
       " 306: 'aintsheperty',\n",
       " 307: 'air',\n",
       " 308: 'airasia',\n",
       " 309: 'airbullet',\n",
       " 310: 'aircraft',\n",
       " 311: 'airhead',\n",
       " 312: 'airhorns',\n",
       " 313: 'airi',\n",
       " 314: 'airing',\n",
       " 315: 'airlift',\n",
       " 316: 'airlines',\n",
       " 317: 'airplane',\n",
       " 318: 'airplanes',\n",
       " 319: 'airport',\n",
       " 320: 'airports',\n",
       " 321: 'airstrikes',\n",
       " 322: 'airwaves',\n",
       " 323: 'aisle',\n",
       " 324: 'aisumage',\n",
       " 325: 'aitchkaycee',\n",
       " 326: 'ajabrown',\n",
       " 327: 'ajw',\n",
       " 328: 'ak',\n",
       " 329: 'aka',\n",
       " 330: 'akame',\n",
       " 331: 'akarb',\n",
       " 332: 'akcsl',\n",
       " 333: 'akgovbillwalker',\n",
       " 334: 'akilah',\n",
       " 335: 'akito',\n",
       " 336: 'akrams',\n",
       " 337: 'aks',\n",
       " 338: 'akumareisu',\n",
       " 339: 'akwa',\n",
       " 340: 'akx',\n",
       " 341: 'akxbskdn',\n",
       " 342: 'al',\n",
       " 343: 'alabama',\n",
       " 344: 'alabamaquake',\n",
       " 345: 'aladdin',\n",
       " 346: 'alameda',\n",
       " 347: 'alamodc',\n",
       " 348: 'alanhahn',\n",
       " 349: 'alarm',\n",
       " 350: 'alarmed',\n",
       " 351: 'alarmems',\n",
       " 352: 'alarming',\n",
       " 353: 'alarmingly',\n",
       " 354: 'alarms',\n",
       " 355: 'alas',\n",
       " 356: 'alaska',\n",
       " 357: 'alaskan',\n",
       " 358: 'alaskas',\n",
       " 359: 'alaskaseafood',\n",
       " 360: 'alba',\n",
       " 361: 'albany',\n",
       " 362: 'albeit',\n",
       " 363: 'alberta',\n",
       " 364: 'albertans',\n",
       " 365: 'albertas',\n",
       " 366: 'albertsons',\n",
       " 367: 'album',\n",
       " 368: 'albums',\n",
       " 369: 'alchemist',\n",
       " 370: 'alcohol',\n",
       " 371: 'alcoholandmetal',\n",
       " 372: 'alcoholismaddiction',\n",
       " 373: 'aldridge',\n",
       " 374: 'alec',\n",
       " 375: 'aleisstokes',\n",
       " 376: 'alekalicante',\n",
       " 377: 'alert',\n",
       " 378: 'alerts',\n",
       " 379: 'alex',\n",
       " 380: 'alexalltimelow',\n",
       " 381: 'alexandrapullin',\n",
       " 382: 'alexandrian',\n",
       " 383: 'alexbelloli',\n",
       " 384: 'alexeivolkov',\n",
       " 385: 'alexhammerstone',\n",
       " 386: 'alexis',\n",
       " 387: 'alexissanchez',\n",
       " 388: 'alexjacobsonpfs',\n",
       " 389: 'alexshipppp',\n",
       " 390: 'alextucker',\n",
       " 391: 'alfapedia',\n",
       " 392: 'algae',\n",
       " 393: 'algeria',\n",
       " 394: 'alhaji',\n",
       " 395: 'alhanda',\n",
       " 396: 'ali',\n",
       " 397: 'alice',\n",
       " 398: 'alien',\n",
       " 399: 'aliens',\n",
       " 400: 'alifaditha',\n",
       " 401: 'align',\n",
       " 402: 'alil',\n",
       " 403: 'alipaper',\n",
       " 404: 'alisonannyoung',\n",
       " 405: 'alive',\n",
       " 406: 'aliveafter',\n",
       " 407: 'alivebut',\n",
       " 408: 'allah',\n",
       " 409: 'allahsfinest',\n",
       " 410: 'allay',\n",
       " 411: 'alldaycumshots',\n",
       " 412: 'allegations',\n",
       " 413: 'alleged',\n",
       " 414: 'allegedly',\n",
       " 415: 'allegiance',\n",
       " 416: 'allenenbot',\n",
       " 417: 'allergic',\n",
       " 418: 'alley',\n",
       " 419: 'alliance',\n",
       " 420: 'allied',\n",
       " 421: 'allies',\n",
       " 422: 'allin',\n",
       " 423: 'allinwithchris',\n",
       " 424: 'alllivesmatter',\n",
       " 425: 'alllll',\n",
       " 426: 'allocating',\n",
       " 427: 'alloosh',\n",
       " 428: 'allotment',\n",
       " 429: 'allow',\n",
       " 430: 'allowed',\n",
       " 431: 'allowing',\n",
       " 432: 'allows',\n",
       " 433: 'alloy',\n",
       " 434: 'allpro',\n",
       " 435: 'allthekidneybeansandsorbetmisha',\n",
       " 436: 'allthenews',\n",
       " 437: 'alltime',\n",
       " 438: 'ally',\n",
       " 439: 'allyinwondrland',\n",
       " 440: 'almighty',\n",
       " 441: 'almost',\n",
       " 442: 'almusafirah',\n",
       " 443: 'alois',\n",
       " 444: 'alone',\n",
       " 445: 'alonedont',\n",
       " 446: 'along',\n",
       " 447: 'alot',\n",
       " 448: 'alphen',\n",
       " 449: 'alps',\n",
       " 450: 'alrasyiditurasya',\n",
       " 451: 'already',\n",
       " 452: 'alright',\n",
       " 453: 'alrightbut',\n",
       " 454: 'alrighty',\n",
       " 455: 'alska',\n",
       " 456: 'also',\n",
       " 457: 'alsowhat',\n",
       " 458: 'alt',\n",
       " 459: 'altamonte',\n",
       " 460: 'alternate',\n",
       " 461: 'alternative',\n",
       " 462: 'alternatives',\n",
       " 463: 'although',\n",
       " 464: 'alton',\n",
       " 465: 'aluminum',\n",
       " 466: 'alves',\n",
       " 467: 'alvinnelson',\n",
       " 468: 'always',\n",
       " 469: 'alwsl',\n",
       " 470: 'alwx',\n",
       " 471: 'ama',\n",
       " 472: 'amageddon',\n",
       " 473: 'amalie',\n",
       " 474: 'amaramin',\n",
       " 475: 'amateur',\n",
       " 476: 'amateurnester',\n",
       " 477: 'amazed',\n",
       " 478: 'amazin',\n",
       " 479: 'amazing',\n",
       " 480: 'amazingness',\n",
       " 481: 'amazon',\n",
       " 482: 'amazondeals',\n",
       " 483: 'amazons',\n",
       " 484: 'amber',\n",
       " 485: 'ambition',\n",
       " 486: 'ambleside',\n",
       " 487: 'ambulance',\n",
       " 488: 'ambulances',\n",
       " 489: 'ambulancewe',\n",
       " 490: 'amcx',\n",
       " 491: 'amdollela',\n",
       " 492: 'ameenshaikh',\n",
       " 493: 'amen',\n",
       " 494: 'amends',\n",
       " 495: 'ameribag',\n",
       " 496: 'america',\n",
       " 497: 'american',\n",
       " 498: 'americanlegion',\n",
       " 499: 'americans',\n",
       " 500: 'americas',\n",
       " 501: 'americayour',\n",
       " 502: 'ames',\n",
       " 503: 'amesocialaction',\n",
       " 504: 'amicos',\n",
       " 505: 'amicospizzato',\n",
       " 506: 'amid',\n",
       " 507: 'amiddleaged',\n",
       " 508: 'amiibos',\n",
       " 509: 'aminakh',\n",
       " 510: 'aminespn',\n",
       " 511: 'amino',\n",
       " 512: 'amirite',\n",
       " 513: 'amirkingkhan',\n",
       " 514: 'amman',\n",
       " 515: 'amo',\n",
       " 516: 'among',\n",
       " 517: 'amongst',\n",
       " 518: 'amp',\n",
       " 519: 'ampamp',\n",
       " 520: 'ampask',\n",
       " 521: 'ampgot',\n",
       " 522: 'amplifier',\n",
       " 523: 'ampmdash',\n",
       " 524: 'ampor',\n",
       " 525: 'ampstart',\n",
       " 526: 'ampstory',\n",
       " 527: 'ampwanted',\n",
       " 528: 'amreading',\n",
       " 529: 'amritsarthats',\n",
       " 530: 'amsal',\n",
       " 531: 'amssummer',\n",
       " 532: 'amsterdam',\n",
       " 533: 'amumumux',\n",
       " 534: 'amznfavorites',\n",
       " 535: 'ana',\n",
       " 536: 'anakin',\n",
       " 537: 'analog',\n",
       " 538: 'analysis',\n",
       " 539: 'anarchicteapot',\n",
       " 540: 'anarchy',\n",
       " 541: 'anathemazhiv',\n",
       " 542: 'anatomy',\n",
       " 543: 'anchor',\n",
       " 544: 'anchorage',\n",
       " 545: 'anchors',\n",
       " 546: 'ancient',\n",
       " 547: 'ancop',\n",
       " 548: 'andchina',\n",
       " 549: 'anders',\n",
       " 550: 'anderson',\n",
       " 551: 'andor',\n",
       " 552: 'andre',\n",
       " 553: 'andrea',\n",
       " 554: 'andrew',\n",
       " 555: 'android',\n",
       " 556: 'androidgames',\n",
       " 557: 'ands',\n",
       " 558: 'andy',\n",
       " 559: 'andygilder',\n",
       " 560: 'anellatulip',\n",
       " 561: 'anew',\n",
       " 562: 'angel',\n",
       " 563: 'angela',\n",
       " 564: 'angeles',\n",
       " 565: 'angelheartnight',\n",
       " 566: 'angelina',\n",
       " 567: 'angelriveralib',\n",
       " 568: 'angels',\n",
       " 569: 'angelstar',\n",
       " 570: 'anger',\n",
       " 571: 'angers',\n",
       " 572: 'angharadjames',\n",
       " 573: 'angioplasty',\n",
       " 574: 'angry',\n",
       " 575: 'angusmacneilsnp',\n",
       " 576: 'anhqdc',\n",
       " 577: 'ani',\n",
       " 578: 'animal',\n",
       " 579: 'animaladvocate',\n",
       " 580: 'animallogic',\n",
       " 581: 'animalrescue',\n",
       " 582: 'animals',\n",
       " 583: 'animations',\n",
       " 584: 'animatronics',\n",
       " 585: 'anime',\n",
       " 586: 'aniston',\n",
       " 587: 'anjem',\n",
       " 588: 'ankle',\n",
       " 589: 'ankles',\n",
       " 590: 'anna',\n",
       " 591: 'annaciclismo',\n",
       " 592: 'annajhm',\n",
       " 593: 'annddd',\n",
       " 594: 'annealiz',\n",
       " 595: 'annihilate',\n",
       " 596: 'annihilated',\n",
       " 597: 'annihilating',\n",
       " 598: 'annihilation',\n",
       " 599: 'anniversary',\n",
       " 600: 'annmarieronan',\n",
       " 601: 'annonymous',\n",
       " 602: 'annoucement',\n",
       " 603: 'announce',\n",
       " 604: 'announced',\n",
       " 605: 'announcement',\n",
       " 606: 'announces',\n",
       " 607: 'annoyed',\n",
       " 608: 'annoying',\n",
       " 609: 'annual',\n",
       " 610: 'anonchimp',\n",
       " 611: 'anonymous',\n",
       " 612: 'another',\n",
       " 613: 'answer',\n",
       " 614: 'answered',\n",
       " 615: 'answers',\n",
       " 616: 'answersplus',\n",
       " 617: 'ant',\n",
       " 618: 'ante',\n",
       " 619: 'anthelmintic',\n",
       " 620: 'anthology',\n",
       " 621: 'anthony',\n",
       " 622: 'anthonys',\n",
       " 623: 'anthrax',\n",
       " 624: 'anthxvy',\n",
       " 625: 'anti',\n",
       " 626: 'antiblight',\n",
       " 627: 'antichrist',\n",
       " 628: 'antifeminist',\n",
       " 629: 'antioch',\n",
       " 630: 'antiochhickoryhollow',\n",
       " 631: 'antiochus',\n",
       " 632: 'antiterrorism',\n",
       " 633: 'antonio',\n",
       " 634: 'antony',\n",
       " 635: 'antpips',\n",
       " 636: 'ants',\n",
       " 637: 'anu',\n",
       " 638: 'anumber',\n",
       " 639: 'anxiety',\n",
       " 640: 'anxietyproblems',\n",
       " 641: 'anxious',\n",
       " 642: 'anybody',\n",
       " 643: 'anymore',\n",
       " 644: 'anymorethats',\n",
       " 645: 'anyone',\n",
       " 646: 'anyoneor',\n",
       " 647: 'anything',\n",
       " 648: 'anythingthere',\n",
       " 649: 'anytime',\n",
       " 650: 'anyway',\n",
       " 651: 'anyways',\n",
       " 652: 'anywhere',\n",
       " 653: 'anza',\n",
       " 654: 'aogashima',\n",
       " 655: 'aoms',\n",
       " 656: 'ap',\n",
       " 657: 'apano',\n",
       " 658: 'apart',\n",
       " 659: 'apartment',\n",
       " 660: 'apartments',\n",
       " 661: 'apaz',\n",
       " 662: 'apc',\n",
       " 663: 'apch',\n",
       " 664: 'apcpdp',\n",
       " 665: 'apd',\n",
       " 666: 'apga',\n",
       " 667: 'aphiabeta',\n",
       " 668: 'aphl',\n",
       " 669: 'aphyr',\n",
       " 670: 'apiece',\n",
       " 671: 'apocalpytic',\n",
       " 672: 'apocalypse',\n",
       " 673: 'apocalypsetunein',\n",
       " 674: 'apocalyptic',\n",
       " 675: 'apollo',\n",
       " 676: 'apollobrown',\n",
       " 677: 'apollobrowns',\n",
       " 678: 'apologies',\n",
       " 679: 'apologise',\n",
       " 680: 'apologize',\n",
       " 681: 'apologized',\n",
       " 682: 'app',\n",
       " 683: 'appalling',\n",
       " 684: 'apparent',\n",
       " 685: 'apparently',\n",
       " 686: 'appeals',\n",
       " 687: 'appeared',\n",
       " 688: 'appears',\n",
       " 689: 'appease',\n",
       " 690: 'apperception',\n",
       " 691: 'appetite',\n",
       " 692: 'applaud',\n",
       " 693: 'apple',\n",
       " 694: 'appleofficlal',\n",
       " 695: 'applications',\n",
       " 696: 'applied',\n",
       " 697: 'applies',\n",
       " 698: 'apply',\n",
       " 699: 'appointment',\n",
       " 700: 'appoints',\n",
       " 701: 'appraisal',\n",
       " 702: 'appreciate',\n",
       " 703: 'appreciated',\n",
       " 704: 'appreciativeinquiry',\n",
       " 705: 'approach',\n",
       " 706: 'approaches',\n",
       " 707: 'approaching',\n",
       " 708: 'appropriate',\n",
       " 709: 'appropriation',\n",
       " 710: 'approval',\n",
       " 711: 'approves',\n",
       " 712: 'appx',\n",
       " 713: 'appys',\n",
       " 714: 'apr',\n",
       " 715: 'april',\n",
       " 716: 'apropos',\n",
       " 717: 'apt',\n",
       " 718: 'aptlyengineerd',\n",
       " 719: 'apts',\n",
       " 720: 'aqua',\n",
       " 721: 'aquarium',\n",
       " 722: 'aquarius',\n",
       " 723: 'ar',\n",
       " 724: 'ara',\n",
       " 725: 'arab',\n",
       " 726: 'arabia',\n",
       " 727: 'arabian',\n",
       " 728: 'arabic',\n",
       " 729: 'arachys',\n",
       " 730: 'arcade',\n",
       " 731: 'arceen',\n",
       " 732: 'archetype',\n",
       " 733: 'archipelagowolves',\n",
       " 734: 'architect',\n",
       " 735: 'architects',\n",
       " 736: 'architecture',\n",
       " 737: 'area',\n",
       " 738: 'areal',\n",
       " 739: 'areas',\n",
       " 740: 'areasminor',\n",
       " 741: 'areavoluntaryinciwebmad',\n",
       " 742: 'areawctv',\n",
       " 743: 'aredeluged',\n",
       " 744: 'arena',\n",
       " 745: 'arenanone',\n",
       " 746: 'arent',\n",
       " 747: 'areva',\n",
       " 748: 'arfur',\n",
       " 749: 'argentaelite',\n",
       " 750: 'argentina',\n",
       " 751: 'argentinean',\n",
       " 752: 'argentings',\n",
       " 753: 'argh',\n",
       " 754: 'argsuppose',\n",
       " 755: 'argue',\n",
       " 756: 'argues',\n",
       " 757: 'argument',\n",
       " 758: 'argus',\n",
       " 759: 'ari',\n",
       " 760: 'ariaahrary',\n",
       " 761: 'ariabrisard',\n",
       " 762: 'arian',\n",
       " 763: 'ariana',\n",
       " 764: 'arianagrande',\n",
       " 765: 'arianareed',\n",
       " 766: 'arin',\n",
       " 767: 'aris',\n",
       " 768: 'ariz',\n",
       " 769: 'arizona',\n",
       " 770: 'arizonadot',\n",
       " 771: 'arizzo',\n",
       " 772: 'arkan',\n",
       " 773: 'arkansas',\n",
       " 774: 'arlington',\n",
       " 775: 'arm',\n",
       " 776: 'armageddon',\n",
       " 777: 'armed',\n",
       " 778: 'armenians',\n",
       " 779: 'armory',\n",
       " 780: 'arms',\n",
       " 781: 'army',\n",
       " 782: 'armys',\n",
       " 783: 'arnhem',\n",
       " 784: 'arobotlegion',\n",
       " 785: 'around',\n",
       " 786: 'aroundthe',\n",
       " 787: 'aroundyoull',\n",
       " 788: 'arovolturi',\n",
       " 789: 'arranged',\n",
       " 790: 'arreat',\n",
       " 791: 'arrest',\n",
       " 792: 'arrested',\n",
       " 793: 'arrestpastornganga',\n",
       " 794: 'arrests',\n",
       " 795: 'arrival',\n",
       " 796: 'arrive',\n",
       " 797: 'arrived',\n",
       " 798: 'arrives',\n",
       " 799: 'arriving',\n",
       " 800: 'arrogant',\n",
       " 801: 'ars',\n",
       " 802: 'arse',\n",
       " 803: 'arsenal',\n",
       " 804: 'arsenals',\n",
       " 805: 'arson',\n",
       " 806: 'arsonattack',\n",
       " 807: 'arsonist',\n",
       " 808: 'arsonistmusic',\n",
       " 809: 'arsonists',\n",
       " 810: 'art',\n",
       " 811: 'artbrut',\n",
       " 812: 'artectura',\n",
       " 813: 'arti',\n",
       " 814: 'articals',\n",
       " 815: 'article',\n",
       " 816: 'articles',\n",
       " 817: 'artificial',\n",
       " 818: 'artillery',\n",
       " 819: 'artist',\n",
       " 820: 'artisteoftheweekfact',\n",
       " 821: 'artists',\n",
       " 822: 'artistsunited',\n",
       " 823: 'arts',\n",
       " 824: 'artwork',\n",
       " 825: 'arvindkejriwal',\n",
       " 826: 'arwx',\n",
       " 827: 'ary',\n",
       " 828: 'asae',\n",
       " 829: 'asap',\n",
       " 830: 'asapalsowatches',\n",
       " 831: 'asb',\n",
       " 832: 'asbury',\n",
       " 833: 'asburyparkpress',\n",
       " 834: 'ascend',\n",
       " 835: 'aseer',\n",
       " 836: 'asf',\n",
       " 837: 'ash',\n",
       " 838: 'ashayo',\n",
       " 839: 'ashberxo',\n",
       " 840: 'ashdod',\n",
       " 841: 'ashenforest',\n",
       " 842: 'ashes',\n",
       " 843: 'ashesashes',\n",
       " 844: 'ashestoashes',\n",
       " 845: 'ashghebranious',\n",
       " 846: 'ashj',\n",
       " 847: 'ashley',\n",
       " 848: 'ashrafiyah',\n",
       " 849: 'ashtonsos',\n",
       " 850: 'ashville',\n",
       " 851: 'asia',\n",
       " 852: 'asian',\n",
       " 853: 'asianshawtyy',\n",
       " 854: 'asics',\n",
       " 855: 'aside',\n",
       " 856: 'asimtanvir',\n",
       " 857: 'ask',\n",
       " 858: 'askcharley',\n",
       " 859: 'askconnor',\n",
       " 860: 'asked',\n",
       " 861: 'askforalaska',\n",
       " 862: 'askhcz',\n",
       " 863: 'askin',\n",
       " 864: 'asking',\n",
       " 865: 'asks',\n",
       " 866: 'asleep',\n",
       " 867: 'aspect',\n",
       " 868: 'aspects',\n",
       " 869: 'asphalt',\n",
       " 870: 'aspiring',\n",
       " 871: 'ass',\n",
       " 872: 'assad',\n",
       " 873: 'assailant',\n",
       " 874: 'assassinkpg',\n",
       " 875: 'assassins',\n",
       " 876: 'assault',\n",
       " 877: 'assembly',\n",
       " 878: 'assertative',\n",
       " 879: 'asses',\n",
       " 880: 'assessment',\n",
       " 881: 'assets',\n",
       " 882: 'asshole',\n",
       " 883: 'assholes',\n",
       " 884: 'assistance',\n",
       " 885: 'assistant',\n",
       " 886: 'assisting',\n",
       " 887: 'assnchat',\n",
       " 888: 'associated',\n",
       " 889: 'association',\n",
       " 890: 'assume',\n",
       " 891: 'assumes',\n",
       " 892: 'assured',\n",
       " 893: 'asswipe',\n",
       " 894: 'asterpuppet',\n",
       " 895: 'astonishing',\n",
       " 896: 'astounding',\n",
       " 897: 'astrakhan',\n",
       " 898: 'astrologian',\n",
       " 899: 'astrology',\n",
       " 900: 'astros',\n",
       " 901: 'astroturfers',\n",
       " 902: 'asukager',\n",
       " 903: 'asylum',\n",
       " 904: 'asymbina',\n",
       " 905: 'atamathon',\n",
       " 906: 'atc',\n",
       " 907: 'atcha',\n",
       " 908: 'atchisonsean',\n",
       " 909: 'atcinema',\n",
       " 910: 'ate',\n",
       " 911: 'atgrannyshouse',\n",
       " 912: 'atheistic',\n",
       " 913: 'athens',\n",
       " 914: 'athlete',\n",
       " 915: 'athletics',\n",
       " 916: 'atk',\n",
       " 917: 'atl',\n",
       " 918: 'atlanta',\n",
       " 919: 'atlantic',\n",
       " 920: 'atlarnxx',\n",
       " 921: 'atlas',\n",
       " 922: 'atlbizchron',\n",
       " 923: 'atleast',\n",
       " 924: 'atlevents',\n",
       " 925: 'atljw',\n",
       " 926: 'atm',\n",
       " 927: 'atmosphere',\n",
       " 928: 'atmospheric',\n",
       " 929: 'atom',\n",
       " 930: 'atombomb',\n",
       " 931: 'atomic',\n",
       " 932: 'atomicbomb',\n",
       " 933: 'att',\n",
       " 934: 'attached',\n",
       " 935: 'attack',\n",
       " 936: 'attackclose',\n",
       " 937: 'attacked',\n",
       " 938: 'attacking',\n",
       " 939: 'attackonstiles',\n",
       " 940: 'attacks',\n",
       " 941: 'attackshare',\n",
       " 942: 'attained',\n",
       " 943: 'attempt',\n",
       " 944: 'attempted',\n",
       " 945: 'attempting',\n",
       " 946: 'attend',\n",
       " 947: 'attendance',\n",
       " 948: 'attended',\n",
       " 949: 'attendees',\n",
       " 950: 'attending',\n",
       " 951: 'attention',\n",
       " 952: 'attic',\n",
       " 953: 'attila',\n",
       " 954: 'attitude',\n",
       " 955: 'attjcdemos',\n",
       " 956: 'attraction',\n",
       " 957: 'attractive',\n",
       " 958: 'atv',\n",
       " 959: 'au',\n",
       " 960: 'aubilenon',\n",
       " 961: 'aubrey',\n",
       " 962: 'auburn',\n",
       " 963: 'auc',\n",
       " 964: 'auckland',\n",
       " 965: 'auction',\n",
       " 966: 'auctions',\n",
       " 967: 'audaciousspunk',\n",
       " 968: 'audacityjamesta',\n",
       " 969: 'audi',\n",
       " 970: 'audience',\n",
       " 971: 'audiences',\n",
       " 972: 'audio',\n",
       " 973: 'audit',\n",
       " 974: 'audreyp',\n",
       " 975: 'aug',\n",
       " 976: 'august',\n",
       " 977: 'aul',\n",
       " 978: 'aunt',\n",
       " 979: 'auntiedote',\n",
       " 980: 'aurora',\n",
       " 981: 'aus',\n",
       " 982: 'ausinstarchitect',\n",
       " 983: 'auspol',\n",
       " 984: 'aussie',\n",
       " 985: 'aussies',\n",
       " 986: 'aust',\n",
       " 987: 'austin',\n",
       " 988: 'austinpearcy',\n",
       " 989: 'australia',\n",
       " 990: 'australian',\n",
       " 991: 'australians',\n",
       " 992: 'australias',\n",
       " 993: 'austrian',\n",
       " 994: 'auth',\n",
       " 995: 'authentic',\n",
       " 996: 'authenticating',\n",
       " 997: 'author',\n",
       " 998: 'authorities',\n",
       " 999: 'authormike',\n",
       " ...}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2idx = {token: idx for idx, token in enumerate(tokens)}\n",
    "idx2token = {idx: token for idx, token in enumerate(tokens)}\n",
    "print(len(idx2token))\n",
    "idx2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] ['deeds', 'reason', '<hashtag>', 'earthquake', 'may', 'allah', 'forgive', 'us']\n",
      "[11] ['residents', 'asked', 'shelter', 'place', 'notified', 'officers', 'evacuation', 'shelter', 'place', 'orders', 'expected']\n",
      "[15] ['<hashtag>', 'rockyfire', 'update', 'california', 'hwy', 'closed', 'directions', 'due', 'lake', 'county', 'fire', '<hashtag>', 'cafire', '<hashtag>', 'wildfires']\n",
      "[16] ['haha', 'south', 'tampa', 'getting', 'flooded', 'hah', 'wait', 'second', 'live', 'south', 'tampa', 'gonna', 'gonna', 'fvck', '<hashtag>', 'flooding']\n",
      "[17] ['rt', 'naayf', 'first', 'accident', 'years', 'turning', 'onto', 'chandanee', 'magu', 'near', 'mma', 'taxi', 'rammed', 'halfway', 'turned', 'everyone', 'conf']\n",
      "[19] ['accident', 'left', 'lane', 'blocked', '<hashtag>', 'manchester', 'rt', 'nb', 'eddy', 'rd', 'stop', 'go', 'traffic', 'back', 'nha', 'delay', 'mins', '<hashtag>', 'traffic']\n",
      "[22] ['anyone', 'need', 'pu', 'tonight', 'play', 'hybrid', 'slayer', 'ps', 'eu', 'hmu', '<mention>', 'codsandscrims', '<mention>', 'empirikgaming', '<mention>', 'codawscrims', '<mention>', 'tpkotc', '<mention>', 'tpfa', '<mention>', 'aftershockorg']\n",
      "[24] ['pilot', 'dies', 'plane', 'crash', 'car', 'festival', '<link>', 'via', '<mention>', 'youtube', '<hashtag>', 'crash', '<hashtag>', 'aircraft', '<hashtag>', 'airplane', '<hashtag>', 'pilot', '<hashtag>', 'death', '<hashtag>', 'accident', '<hashtag>', 'carfest']\n",
      "[26] ['rt', '<mention>', 'ophiuchus', '<hashtag>', 'love', '<hashtag>', 'truelove', '<hashtag>', 'romance', 'lith', '<hashtag>', 'voodoo', '<hashtag>', 'seduction', '<hashtag>', 'astrology', '<hashtag>', 'rtrrt', '<hashtag>', 'lotz', '<hashtag>', 'apocalypse', '<hashtag>', 'armageddon', '<hashtag>', 'pla']\n",
      "[28] ['<hashtag>', 'news', '<hashtag>', 'hostages', '<hashtag>', 'libya', '<link>', '<hashtag>', 'india', '<hashtag>', 'terrorism', '<hashtag>', 'africa', '<hashtag>', 'ap', '<hashtag>', 'ts', '<hashtag>', 'nri', '<hashtag>', 'news', '<hashtag>', 'trs', '<hashtag>', 'tdp', '<hashtag>', 'bjp', '<link>']\n",
      "[30] ['rare', 'insight', '<hashtag>', 'terror', 'fight', '<link>', '<hashtag>', 'cameroon', '<hashtag>', 'usa', '<hashtag>', 'whitehouse', '<hashtag>', 'es', '<hashtag>', 'fr', '<hashtag>', 'nigeria', '<hashtag>', 'uk', '<hashtag>', 'africa', '<hashtag>', 'de', '<hashtag>', 'ca', '<hashtag>', 'au', '<hashtag>', 'jp']\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for tweet in x_train_tokens:\n",
    "    if len(tweet) > max_length:\n",
    "        max_length = len(tweet)\n",
    "        print('[{}] {}'.format(max_length, tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] ['happened', 'terrible', 'car', 'crash']\n",
      "[8] ['heard', '<hashtag>', 'earthquake', 'different', 'cities', 'stay', 'safe', 'everyone']\n",
      "[9] ['forest', 'fire', 'spot', 'pond', 'fleeing', 'across', 'street', 'cannot', 'save']\n",
      "[12] ['birmingham', 'wholesale', 'market', 'ablaze', 'bbc', 'news', 'fire', 'breaks', 'birminghams', 'wholesale', 'market', '<link>']\n",
      "[15] ['diss', 'song', 'people', 'take', 'thing', 'run', 'smh', 'eye', 'opener', 'though', 'set', 'game', 'ablaze', '<mention>', 'cyhitheprynce']\n",
      "[19] ['ir', 'icemoon', 'aftershock', '<link>', '<mention>', 'djicemoon', '<hashtag>', 'dubstep', '<hashtag>', 'trapmusic', '<hashtag>', 'dnb', '<hashtag>', 'edm', '<hashtag>', 'dance', '<hashtag>', 'ices', '<link>']\n",
      "[27] ['hundreds', 'migrants', 'feared', 'drowned', 'libya', '<link>', '<hashtag>', 'news', '<hashtag>', 'bbc', '<hashtag>', 'cnn', '<hashtag>', 'msnbc', '<hashtag>', 'nyt', '<hashtag>', 'tcot', '<hashtag>', '<hashtag>', '<hashtag>', 'ccot', '<hashtag>', '<hashtag>', 'p', '<hashtag>', 'ap']\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for tweet in x_test_tokens:\n",
    "    if len(tweet) > max_length:\n",
    "        max_length = len(tweet)\n",
    "        print('[{}] {}'.format(max_length, tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = list(map(lambda tweet: [token2idx[token] for token in tweet], x_train_tokens))\n",
    "x_test = list(map(lambda tweet: [token2idx[token] for token in tweet], x_test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(\n",
    "    x_train, \n",
    "    maxlen=sequence_length, \n",
    "    padding='post', \n",
    "    truncating='post')\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(\n",
    "    x_test, \n",
    "    maxlen=sequence_length, \n",
    "    padding='post', \n",
    "    truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 30)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 30)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetModel(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(TweetModel, self).__init__()\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.lstm1 = keras.layers.LSTM(512, return_sequences=True)\n",
    "        self.dist1 = keras.layers.TimeDistributed(keras.layers.Dropout(rate=0.5))\n",
    "        \n",
    "        self.lstm2 = keras.layers.LSTM(256)\n",
    "        self.drop2 = keras.layers.Dropout(rate = 0.25)\n",
    "    \n",
    "        self.dense3 = keras.layers.Dense(units=128, activation='relu')\n",
    "        self.drop3 = keras.layers.Dropout(rate = 0.2)\n",
    "\n",
    "        self.dense4 = keras.layers.Dense(units=1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        layer1 = self.lstm1(x)\n",
    "        layer1 = self.dist1(layer1)\n",
    "        \n",
    "        layer2 = self.lstm2(layer1)\n",
    "        layer2 = self.drop2(layer2)\n",
    "\n",
    "        layer3 = self.dense3(layer2)\n",
    "        layer3 = self.drop3(layer3)\n",
    "\n",
    "        y = self.dense4(layer3)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TweetModel(len(tokens), sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "iterations = x_train.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset = dataset.shuffle(10000)\n",
    "dataset = dataset.prefetch(10000)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "dataset_iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, features, labels, training=True):\n",
    "    y = model(features, training)\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    loss = -tf.reduce_mean(labels * tf.math.log(y) + (1 - labels) * tf.math.log(1 - y))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(model, features, labels, training=False):\n",
    "    y = model(features, training)\n",
    "    prediction = tf.cast(y > 0.5, tf.int64)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, labels), tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 [   1/  59] loss= 0.6933 acc=57.81%\n",
      "Epoch   1 [   6/  59] loss= 2.4677 acc=48.83%\n",
      "Epoch   1 [  11/  59] loss= 0.6871 acc=57.81%\n",
      "Epoch   1 [  16/  59] loss= 0.6879 acc=56.25%\n",
      "Epoch   1 [  21/  59] loss= 0.6866 acc=56.25%\n",
      "Epoch   1 [  26/  59] loss= 0.6867 acc=56.25%\n",
      "Epoch   1 [  31/  59] loss= 0.7020 acc=51.56%\n",
      "Epoch   1 [  36/  59] loss= 0.6955 acc=53.12%\n",
      "Epoch   1 [  41/  59] loss= 0.6866 acc=56.25%\n",
      "Epoch   1 [  46/  59] loss= 0.6834 acc=57.81%\n",
      "Epoch   1 [  51/  59] loss= 0.6817 acc=57.81%\n",
      "Epoch   1 [  56/  59] loss= 0.6957 acc=53.91%\n",
      "*** Epoch   1 TRAINING loss= 0.7389 acc=56.52% VALIDATION loss= 0.6381 acc=70.49% ***\n",
      "\n",
      "Epoch   2 [   1/  59] loss= 0.6899 acc=55.47%\n",
      "Epoch   2 [   6/  59] loss= 0.6792 acc=58.59%\n",
      "Epoch   2 [  11/  59] loss= 0.6929 acc=53.91%\n",
      "Epoch   2 [  16/  59] loss= 0.7028 acc=49.22%\n",
      "Epoch   2 [  21/  59] loss= 0.6779 acc=60.16%\n",
      "Epoch   2 [  26/  59] loss= 0.6841 acc=57.03%\n",
      "Epoch   2 [  31/  59] loss= 0.6789 acc=58.59%\n",
      "Epoch   2 [  36/  59] loss= 0.6906 acc=53.91%\n",
      "Epoch   2 [  41/  59] loss= 0.6847 acc=57.81%\n",
      "Epoch   2 [  46/  59] loss= 0.6946 acc=50.78%\n",
      "Epoch   2 [  51/  59] loss= 0.6817 acc=58.59%\n",
      "Epoch   2 [  56/  59] loss= 0.6902 acc=54.69%\n",
      "*** Epoch   2 TRAINING loss= 0.6845 acc=57.04% VALIDATION loss= 0.6878 acc=55.74% ***\n",
      "\n",
      "Epoch   3 [   1/  59] loss= 0.6872 acc=56.25%\n",
      "Epoch   3 [   6/  59] loss= 0.6764 acc=59.38%\n",
      "Epoch   3 [  11/  59] loss= 0.6782 acc=59.38%\n",
      "Epoch   3 [  16/  59] loss= 0.6864 acc=56.25%\n",
      "Epoch   3 [  21/  59] loss= 0.6865 acc=56.25%\n",
      "Epoch   3 [  26/  59] loss= 0.6727 acc=63.28%\n",
      "Epoch   3 [  31/  59] loss= 0.6782 acc=59.38%\n",
      "Epoch   3 [  36/  59] loss= 0.6815 acc=57.81%\n",
      "Epoch   3 [  41/  59] loss= 0.6790 acc=58.59%\n",
      "Epoch   3 [  46/  59] loss= 0.6933 acc=53.91%\n",
      "Epoch   3 [  51/  59] loss= 0.6720 acc=61.72%\n",
      "Epoch   3 [  56/  59] loss= 0.6747 acc=60.94%\n",
      "*** Epoch   3 TRAINING loss= 0.6847 acc=57.02% VALIDATION loss= 0.6792 acc=59.02% ***\n",
      "\n",
      "Epoch   4 [   1/  59] loss= 0.6660 acc=64.84%\n",
      "Epoch   4 [   6/  59] loss= 0.6762 acc=60.16%\n",
      "Epoch   4 [  11/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch   4 [  16/  59] loss= 0.6788 acc=58.59%\n",
      "Epoch   4 [  21/  59] loss= 0.6731 acc=60.16%\n",
      "Epoch   4 [  26/  59] loss= 0.6997 acc=52.34%\n",
      "Epoch   4 [  31/  59] loss= 0.6834 acc=57.03%\n",
      "Epoch   4 [  36/  59] loss= 0.6979 acc=51.56%\n",
      "Epoch   4 [  41/  59] loss= 0.6814 acc=57.81%\n",
      "Epoch   4 [  46/  59] loss= 0.6779 acc=59.38%\n",
      "Epoch   4 [  51/  59] loss= 0.6817 acc=57.81%\n",
      "Epoch   4 [  56/  59] loss= 0.6962 acc=51.56%\n",
      "*** Epoch   4 TRAINING loss= 0.6835 acc=57.03% VALIDATION loss= 0.6827 acc=57.38% ***\n",
      "\n",
      "Epoch   5 [   1/  59] loss= 0.6926 acc=53.12%\n",
      "Epoch   5 [   6/  59] loss= 0.6800 acc=58.59%\n",
      "Epoch   5 [  11/  59] loss= 0.6575 acc=67.97%\n",
      "Epoch   5 [  16/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch   5 [  21/  59] loss= 0.6730 acc=60.94%\n",
      "Epoch   5 [  26/  59] loss= 0.7002 acc=50.78%\n",
      "Epoch   5 [  31/  59] loss= 0.6589 acc=65.62%\n",
      "Epoch   5 [  36/  59] loss= 0.6787 acc=58.59%\n",
      "Epoch   5 [  41/  59] loss= 0.6719 acc=60.94%\n",
      "Epoch   5 [  46/  59] loss= 0.6788 acc=58.59%\n",
      "Epoch   5 [  51/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch   5 [  56/  59] loss= 0.6616 acc=64.84%\n",
      "*** Epoch   5 TRAINING loss= 0.6833 acc=57.10% VALIDATION loss= 0.7050 acc=49.18% ***\n",
      "\n",
      "Epoch   6 [   1/  59] loss= 0.6941 acc=53.12%\n",
      "Epoch   6 [   6/  59] loss= 0.6683 acc=62.50%\n",
      "Epoch   6 [  11/  59] loss= 0.6678 acc=62.50%\n",
      "Epoch   6 [  16/  59] loss= 0.6973 acc=52.34%\n",
      "Epoch   6 [  21/  59] loss= 0.6762 acc=59.38%\n",
      "Epoch   6 [  26/  59] loss= 0.6762 acc=59.38%\n",
      "Epoch   6 [  31/  59] loss= 0.7016 acc=50.78%\n",
      "Epoch   6 [  36/  59] loss= 0.7013 acc=50.78%\n",
      "Epoch   6 [  41/  59] loss= 0.6901 acc=54.69%\n",
      "Epoch   6 [  46/  59] loss= 0.6765 acc=59.38%\n",
      "Epoch   6 [  51/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch   6 [  56/  59] loss= 0.6919 acc=53.91%\n",
      "*** Epoch   6 TRAINING loss= 0.6832 acc=57.06% VALIDATION loss= 0.6912 acc=54.10% ***\n",
      "\n",
      "Epoch   7 [   1/  59] loss= 0.6875 acc=55.47%\n",
      "Epoch   7 [   6/  59] loss= 0.7040 acc=49.22%\n",
      "Epoch   7 [  11/  59] loss= 0.6978 acc=51.56%\n",
      "Epoch   7 [  16/  59] loss= 0.6791 acc=58.59%\n",
      "Epoch   7 [  21/  59] loss= 0.6595 acc=65.62%\n",
      "Epoch   7 [  26/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch   7 [  31/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch   7 [  36/  59] loss= 0.6926 acc=53.91%\n",
      "Epoch   7 [  41/  59] loss= 0.7112 acc=47.66%\n",
      "Epoch   7 [  46/  59] loss= 0.6763 acc=59.38%\n",
      "Epoch   7 [  51/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch   7 [  56/  59] loss= 0.6899 acc=54.69%\n",
      "*** Epoch   7 TRAINING loss= 0.6834 acc=57.00% VALIDATION loss= 0.6733 acc=60.66% ***\n",
      "\n",
      "Epoch   8 [   1/  59] loss= 0.6531 acc=67.97%\n",
      "Epoch   8 [   6/  59] loss= 0.6965 acc=52.34%\n",
      "Epoch   8 [  11/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch   8 [  16/  59] loss= 0.6714 acc=60.94%\n",
      "Epoch   8 [  21/  59] loss= 0.7227 acc=44.53%\n",
      "Epoch   8 [  26/  59] loss= 0.6785 acc=58.59%\n",
      "Epoch   8 [  31/  59] loss= 0.6948 acc=53.12%\n",
      "Epoch   8 [  36/  59] loss= 0.6790 acc=58.59%\n",
      "Epoch   8 [  41/  59] loss= 0.6973 acc=51.56%\n",
      "Epoch   8 [  46/  59] loss= 0.6949 acc=52.34%\n",
      "Epoch   8 [  51/  59] loss= 0.6760 acc=60.16%\n",
      "Epoch   8 [  56/  59] loss= 0.6720 acc=61.72%\n",
      "*** Epoch   8 TRAINING loss= 0.6837 acc=56.95% VALIDATION loss= 0.6579 acc=67.21% ***\n",
      "\n",
      "Epoch   9 [   1/  59] loss= 0.6795 acc=58.59%\n",
      "Epoch   9 [   6/  59] loss= 0.6893 acc=54.69%\n",
      "Epoch   9 [  11/  59] loss= 0.6751 acc=60.16%\n",
      "Epoch   9 [  16/  59] loss= 0.6728 acc=60.94%\n",
      "Epoch   9 [  21/  59] loss= 0.6964 acc=52.34%\n",
      "Epoch   9 [  26/  59] loss= 0.6920 acc=53.91%\n",
      "Epoch   9 [  31/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch   9 [  36/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch   9 [  41/  59] loss= 0.7095 acc=47.66%\n",
      "Epoch   9 [  46/  59] loss= 0.6898 acc=54.69%\n",
      "Epoch   9 [  51/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch   9 [  56/  59] loss= 0.6832 acc=57.03%\n",
      "*** Epoch   9 TRAINING loss= 0.6831 acc=57.10% VALIDATION loss= 0.7057 acc=49.18% ***\n",
      "\n",
      "Epoch  10 [   1/  59] loss= 0.6967 acc=52.34%\n",
      "Epoch  10 [   6/  59] loss= 0.6588 acc=65.62%\n",
      "Epoch  10 [  11/  59] loss= 0.6715 acc=60.94%\n",
      "Epoch  10 [  16/  59] loss= 0.7002 acc=51.56%\n",
      "Epoch  10 [  21/  59] loss= 0.6785 acc=58.59%\n",
      "Epoch  10 [  26/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  10 [  31/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  10 [  36/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  10 [  41/  59] loss= 0.6789 acc=58.59%\n",
      "Epoch  10 [  46/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  10 [  51/  59] loss= 0.7023 acc=50.00%\n",
      "Epoch  10 [  56/  59] loss= 0.6853 acc=56.25%\n",
      "*** Epoch  10 TRAINING loss= 0.6835 acc=56.97% VALIDATION loss= 0.6606 acc=65.57% ***\n",
      "\n",
      "Epoch  11 [   1/  59] loss= 0.6936 acc=53.12%\n",
      "Epoch  11 [   6/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  11 [  11/  59] loss= 0.6711 acc=61.72%\n",
      "Epoch  11 [  16/  59] loss= 0.6812 acc=57.81%\n",
      "Epoch  11 [  21/  59] loss= 0.6752 acc=60.16%\n",
      "Epoch  11 [  26/  59] loss= 0.6691 acc=62.50%\n",
      "Epoch  11 [  31/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  11 [  36/  59] loss= 0.6879 acc=55.47%\n",
      "Epoch  11 [  41/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  11 [  46/  59] loss= 0.7013 acc=51.56%\n",
      "Epoch  11 [  51/  59] loss= 0.6708 acc=60.94%\n",
      "Epoch  11 [  56/  59] loss= 0.6930 acc=53.91%\n",
      "*** Epoch  11 TRAINING loss= 0.6834 acc=57.06% VALIDATION loss= 0.6919 acc=54.10% ***\n",
      "\n",
      "Epoch  12 [   1/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  12 [   6/  59] loss= 0.6673 acc=62.50%\n",
      "Epoch  12 [  11/  59] loss= 0.6997 acc=51.56%\n",
      "Epoch  12 [  16/  59] loss= 0.6667 acc=62.50%\n",
      "Epoch  12 [  21/  59] loss= 0.6785 acc=58.59%\n",
      "Epoch  12 [  26/  59] loss= 0.7005 acc=51.56%\n",
      "Epoch  12 [  31/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  12 [  36/  59] loss= 0.6786 acc=58.59%\n",
      "Epoch  12 [  41/  59] loss= 0.6919 acc=53.91%\n",
      "Epoch  12 [  46/  59] loss= 0.6730 acc=60.94%\n",
      "Epoch  12 [  51/  59] loss= 0.7017 acc=50.00%\n",
      "Epoch  12 [  56/  59] loss= 0.6915 acc=53.91%\n",
      "*** Epoch  12 TRAINING loss= 0.6833 acc=57.03% VALIDATION loss= 0.6824 acc=57.38% ***\n",
      "\n",
      "Epoch  13 [   1/  59] loss= 0.6588 acc=66.41%\n",
      "Epoch  13 [   6/  59] loss= 0.6709 acc=61.72%\n",
      "Epoch  13 [  11/  59] loss= 0.6710 acc=61.72%\n",
      "Epoch  13 [  16/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  13 [  21/  59] loss= 0.6938 acc=53.12%\n",
      "Epoch  13 [  26/  59] loss= 0.6938 acc=53.12%\n",
      "Epoch  13 [  31/  59] loss= 0.6751 acc=60.16%\n",
      "Epoch  13 [  36/  59] loss= 0.6645 acc=64.06%\n",
      "Epoch  13 [  41/  59] loss= 0.6614 acc=64.84%\n",
      "Epoch  13 [  46/  59] loss= 0.6743 acc=60.16%\n",
      "Epoch  13 [  51/  59] loss= 0.6787 acc=58.59%\n",
      "Epoch  13 [  56/  59] loss= 0.6855 acc=56.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch  13 TRAINING loss= 0.6833 acc=57.04% VALIDATION loss= 0.6870 acc=55.74% ***\n",
      "\n",
      "Epoch  14 [   1/  59] loss= 0.6968 acc=52.34%\n",
      "Epoch  14 [   6/  59] loss= 0.6940 acc=53.12%\n",
      "Epoch  14 [  11/  59] loss= 0.6791 acc=58.59%\n",
      "Epoch  14 [  16/  59] loss= 0.6813 acc=57.81%\n",
      "Epoch  14 [  21/  59] loss= 0.6649 acc=64.06%\n",
      "Epoch  14 [  26/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  14 [  31/  59] loss= 0.6747 acc=60.16%\n",
      "Epoch  14 [  36/  59] loss= 0.6922 acc=53.91%\n",
      "Epoch  14 [  41/  59] loss= 0.7038 acc=50.00%\n",
      "Epoch  14 [  46/  59] loss= 0.6720 acc=60.94%\n",
      "Epoch  14 [  51/  59] loss= 0.6544 acc=67.19%\n",
      "Epoch  14 [  56/  59] loss= 0.6787 acc=58.59%\n",
      "*** Epoch  14 TRAINING loss= 0.6831 acc=57.12% VALIDATION loss= 0.7163 acc=45.90% ***\n",
      "\n",
      "Epoch  15 [   1/  59] loss= 0.6949 acc=53.12%\n",
      "Epoch  15 [   6/  59] loss= 0.6741 acc=60.16%\n",
      "Epoch  15 [  11/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  15 [  16/  59] loss= 0.6978 acc=51.56%\n",
      "Epoch  15 [  21/  59] loss= 0.6952 acc=52.34%\n",
      "Epoch  15 [  26/  59] loss= 0.6776 acc=59.38%\n",
      "Epoch  15 [  31/  59] loss= 0.6731 acc=60.94%\n",
      "Epoch  15 [  36/  59] loss= 0.6875 acc=55.47%\n",
      "Epoch  15 [  41/  59] loss= 0.6679 acc=62.50%\n",
      "Epoch  15 [  46/  59] loss= 0.6695 acc=61.72%\n",
      "Epoch  15 [  51/  59] loss= 0.6927 acc=53.91%\n",
      "Epoch  15 [  56/  59] loss= 0.6954 acc=53.12%\n",
      "*** Epoch  15 TRAINING loss= 0.6831 acc=57.12% VALIDATION loss= 0.7186 acc=45.90% ***\n",
      "\n",
      "Epoch  16 [   1/  59] loss= 0.6908 acc=54.69%\n",
      "Epoch  16 [   6/  59] loss= 0.7008 acc=51.56%\n",
      "Epoch  16 [  11/  59] loss= 0.6931 acc=53.91%\n",
      "Epoch  16 [  16/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  16 [  21/  59] loss= 0.6711 acc=60.94%\n",
      "Epoch  16 [  26/  59] loss= 0.6636 acc=63.28%\n",
      "Epoch  16 [  31/  59] loss= 0.6834 acc=57.03%\n",
      "Epoch  16 [  36/  59] loss= 0.6784 acc=58.59%\n",
      "Epoch  16 [  41/  59] loss= 0.6931 acc=53.91%\n",
      "Epoch  16 [  46/  59] loss= 0.6857 acc=56.25%\n",
      "Epoch  16 [  51/  59] loss= 0.6739 acc=60.16%\n",
      "Epoch  16 [  56/  59] loss= 0.6810 acc=57.81%\n",
      "*** Epoch  16 TRAINING loss= 0.6833 acc=57.02% VALIDATION loss= 0.6777 acc=59.02% ***\n",
      "\n",
      "Epoch  17 [   1/  59] loss= 0.6570 acc=66.41%\n",
      "Epoch  17 [   6/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  17 [  11/  59] loss= 0.6728 acc=60.94%\n",
      "Epoch  17 [  16/  59] loss= 0.6941 acc=53.12%\n",
      "Epoch  17 [  21/  59] loss= 0.6984 acc=51.56%\n",
      "Epoch  17 [  26/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  17 [  31/  59] loss= 0.6977 acc=51.56%\n",
      "Epoch  17 [  36/  59] loss= 0.6934 acc=53.12%\n",
      "Epoch  17 [  41/  59] loss= 0.6692 acc=62.50%\n",
      "Epoch  17 [  46/  59] loss= 0.6791 acc=58.59%\n",
      "Epoch  17 [  51/  59] loss= 0.6703 acc=61.72%\n",
      "Epoch  17 [  56/  59] loss= 0.6614 acc=64.84%\n",
      "*** Epoch  17 TRAINING loss= 0.6835 acc=56.98% VALIDATION loss= 0.6638 acc=63.93% ***\n",
      "\n",
      "Epoch  18 [   1/  59] loss= 0.6766 acc=59.38%\n",
      "Epoch  18 [   6/  59] loss= 0.6744 acc=60.16%\n",
      "Epoch  18 [  11/  59] loss= 0.6991 acc=51.56%\n",
      "Epoch  18 [  16/  59] loss= 0.6946 acc=53.12%\n",
      "Epoch  18 [  21/  59] loss= 0.6944 acc=53.12%\n",
      "Epoch  18 [  26/  59] loss= 0.6789 acc=58.59%\n",
      "Epoch  18 [  31/  59] loss= 0.6750 acc=60.16%\n",
      "Epoch  18 [  36/  59] loss= 0.6895 acc=54.69%\n",
      "Epoch  18 [  41/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  18 [  46/  59] loss= 0.6917 acc=53.91%\n",
      "Epoch  18 [  51/  59] loss= 0.6959 acc=52.34%\n",
      "Epoch  18 [  56/  59] loss= 0.6897 acc=54.69%\n",
      "*** Epoch  18 TRAINING loss= 0.6834 acc=57.02% VALIDATION loss= 0.6777 acc=59.02% ***\n",
      "\n",
      "Epoch  19 [   1/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  19 [   6/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  19 [  11/  59] loss= 0.6615 acc=64.06%\n",
      "Epoch  19 [  16/  59] loss= 0.6707 acc=60.94%\n",
      "Epoch  19 [  21/  59] loss= 0.6886 acc=55.47%\n",
      "Epoch  19 [  26/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  19 [  31/  59] loss= 0.6785 acc=58.59%\n",
      "Epoch  19 [  36/  59] loss= 0.6764 acc=59.38%\n",
      "Epoch  19 [  41/  59] loss= 0.6942 acc=53.12%\n",
      "Epoch  19 [  46/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  19 [  51/  59] loss= 0.6995 acc=50.78%\n",
      "Epoch  19 [  56/  59] loss= 0.6853 acc=56.25%\n",
      "*** Epoch  19 TRAINING loss= 0.6835 acc=57.00% VALIDATION loss= 0.6741 acc=60.66% ***\n",
      "\n",
      "Epoch  20 [   1/  59] loss= 0.6913 acc=53.91%\n",
      "Epoch  20 [   6/  59] loss= 0.6956 acc=52.34%\n",
      "Epoch  20 [  11/  59] loss= 0.6916 acc=53.91%\n",
      "Epoch  20 [  16/  59] loss= 0.6914 acc=53.91%\n",
      "Epoch  20 [  21/  59] loss= 0.6740 acc=60.94%\n",
      "Epoch  20 [  26/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  20 [  31/  59] loss= 0.6834 acc=57.03%\n",
      "Epoch  20 [  36/  59] loss= 0.6749 acc=60.16%\n",
      "Epoch  20 [  41/  59] loss= 0.6879 acc=55.47%\n",
      "Epoch  20 [  46/  59] loss= 0.6761 acc=59.38%\n",
      "Epoch  20 [  51/  59] loss= 0.6857 acc=56.25%\n",
      "Epoch  20 [  56/  59] loss= 0.7047 acc=50.00%\n",
      "*** Epoch  20 TRAINING loss= 0.6837 acc=56.98% VALIDATION loss= 0.6625 acc=63.93% ***\n",
      "\n",
      "Epoch  21 [   1/  59] loss= 0.7021 acc=50.78%\n",
      "Epoch  21 [   6/  59] loss= 0.6740 acc=60.16%\n",
      "Epoch  21 [  11/  59] loss= 0.6947 acc=53.12%\n",
      "Epoch  21 [  16/  59] loss= 0.6788 acc=58.59%\n",
      "Epoch  21 [  21/  59] loss= 0.6769 acc=59.38%\n",
      "Epoch  21 [  26/  59] loss= 0.6896 acc=54.69%\n",
      "Epoch  21 [  31/  59] loss= 0.6958 acc=52.34%\n",
      "Epoch  21 [  36/  59] loss= 0.6730 acc=60.94%\n",
      "Epoch  21 [  41/  59] loss= 0.6732 acc=60.94%\n",
      "Epoch  21 [  46/  59] loss= 0.7043 acc=49.22%\n",
      "Epoch  21 [  51/  59] loss= 0.6722 acc=60.94%\n",
      "Epoch  21 [  56/  59] loss= 0.7025 acc=50.78%\n",
      "*** Epoch  21 TRAINING loss= 0.6832 acc=57.10% VALIDATION loss= 0.7078 acc=49.18% ***\n",
      "\n",
      "Epoch  22 [   1/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  22 [   6/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  22 [  11/  59] loss= 0.7155 acc=46.09%\n",
      "Epoch  22 [  16/  59] loss= 0.6923 acc=53.91%\n",
      "Epoch  22 [  21/  59] loss= 0.6946 acc=53.12%\n",
      "Epoch  22 [  26/  59] loss= 0.6720 acc=60.94%\n",
      "Epoch  22 [  31/  59] loss= 0.6741 acc=60.16%\n",
      "Epoch  22 [  36/  59] loss= 0.6785 acc=58.59%\n",
      "Epoch  22 [  41/  59] loss= 0.6906 acc=54.69%\n",
      "Epoch  22 [  46/  59] loss= 0.6858 acc=56.25%\n",
      "Epoch  22 [  51/  59] loss= 0.6904 acc=54.69%\n",
      "Epoch  22 [  56/  59] loss= 0.6741 acc=60.16%\n",
      "*** Epoch  22 TRAINING loss= 0.6835 acc=56.99% VALIDATION loss= 0.6684 acc=62.30% ***\n",
      "\n",
      "Epoch  23 [   1/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  23 [   6/  59] loss= 0.6685 acc=62.50%\n",
      "Epoch  23 [  11/  59] loss= 0.6686 acc=62.50%\n",
      "Epoch  23 [  16/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  23 [  21/  59] loss= 0.6982 acc=51.56%\n",
      "Epoch  23 [  26/  59] loss= 0.6540 acc=67.97%\n",
      "Epoch  23 [  31/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  23 [  36/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  23 [  41/  59] loss= 0.6493 acc=68.75%\n",
      "Epoch  23 [  46/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  23 [  51/  59] loss= 0.6719 acc=60.94%\n",
      "Epoch  23 [  56/  59] loss= 0.6672 acc=62.50%\n",
      "*** Epoch  23 TRAINING loss= 0.6832 acc=57.06% VALIDATION loss= 0.6917 acc=54.10% ***\n",
      "\n",
      "Epoch  24 [   1/  59] loss= 0.6674 acc=62.50%\n",
      "Epoch  24 [   6/  59] loss= 0.6920 acc=53.91%\n",
      "Epoch  24 [  11/  59] loss= 0.6938 acc=53.12%\n",
      "Epoch  24 [  16/  59] loss= 0.7098 acc=46.88%\n",
      "Epoch  24 [  21/  59] loss= 0.7147 acc=45.31%\n",
      "Epoch  24 [  26/  59] loss= 0.6751 acc=60.16%\n",
      "Epoch  24 [  31/  59] loss= 0.6812 acc=57.81%\n",
      "Epoch  24 [  36/  59] loss= 0.6703 acc=61.72%\n",
      "Epoch  24 [  41/  59] loss= 0.6788 acc=58.59%\n",
      "Epoch  24 [  46/  59] loss= 0.6787 acc=58.59%\n",
      "Epoch  24 [  51/  59] loss= 0.6902 acc=54.69%\n",
      "Epoch  24 [  56/  59] loss= 0.6973 acc=52.34%\n",
      "*** Epoch  24 TRAINING loss= 0.6834 acc=57.00% VALIDATION loss= 0.6725 acc=60.66% ***\n",
      "\n",
      "Epoch  25 [   1/  59] loss= 0.7109 acc=47.66%\n",
      "Epoch  25 [   6/  59] loss= 0.6921 acc=53.91%\n",
      "Epoch  25 [  11/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  25 [  16/  59] loss= 0.6966 acc=52.34%\n",
      "Epoch  25 [  21/  59] loss= 0.6789 acc=58.59%\n",
      "Epoch  25 [  26/  59] loss= 0.7192 acc=43.75%\n",
      "Epoch  25 [  31/  59] loss= 0.6718 acc=61.72%\n",
      "Epoch  25 [  36/  59] loss= 0.6908 acc=53.91%\n",
      "Epoch  25 [  41/  59] loss= 0.6799 acc=58.59%\n",
      "Epoch  25 [  46/  59] loss= 0.6645 acc=64.84%\n",
      "Epoch  25 [  51/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  25 [  56/  59] loss= 0.6832 acc=57.03%\n",
      "*** Epoch  25 TRAINING loss= 0.6835 acc=57.00% VALIDATION loss= 0.6725 acc=60.66% ***\n",
      "\n",
      "Epoch  26 [   1/  59] loss= 0.6786 acc=58.59%\n",
      "Epoch  26 [   6/  59] loss= 0.6736 acc=60.16%\n",
      "Epoch  26 [  11/  59] loss= 0.6834 acc=57.03%\n",
      "Epoch  26 [  16/  59] loss= 0.6733 acc=60.16%\n",
      "Epoch  26 [  21/  59] loss= 0.6629 acc=63.28%\n",
      "Epoch  26 [  26/  59] loss= 0.6835 acc=57.03%\n",
      "Epoch  26 [  31/  59] loss= 0.6835 acc=57.03%\n",
      "Epoch  26 [  36/  59] loss= 0.6858 acc=56.25%\n",
      "Epoch  26 [  41/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  26 [  46/  59] loss= 0.6876 acc=55.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  26 [  51/  59] loss= 0.6541 acc=67.97%\n",
      "Epoch  26 [  56/  59] loss= 0.7040 acc=49.22%\n",
      "*** Epoch  26 TRAINING loss= 0.6832 acc=57.08% VALIDATION loss= 0.6995 acc=50.82% ***\n",
      "\n",
      "Epoch  27 [   1/  59] loss= 0.6812 acc=57.81%\n",
      "Epoch  27 [   6/  59] loss= 0.6748 acc=60.16%\n",
      "Epoch  27 [  11/  59] loss= 0.6899 acc=54.69%\n",
      "Epoch  27 [  16/  59] loss= 0.6900 acc=54.69%\n",
      "Epoch  27 [  21/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  27 [  26/  59] loss= 0.6991 acc=51.56%\n",
      "Epoch  27 [  31/  59] loss= 0.6658 acc=63.28%\n",
      "Epoch  27 [  36/  59] loss= 0.6959 acc=52.34%\n",
      "Epoch  27 [  41/  59] loss= 0.6581 acc=66.41%\n",
      "Epoch  27 [  46/  59] loss= 0.7028 acc=50.00%\n",
      "Epoch  27 [  51/  59] loss= 0.6790 acc=58.59%\n",
      "Epoch  27 [  56/  59] loss= 0.6726 acc=60.94%\n",
      "*** Epoch  27 TRAINING loss= 0.6832 acc=57.08% VALIDATION loss= 0.7006 acc=50.82% ***\n",
      "\n",
      "Epoch  28 [   1/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  28 [   6/  59] loss= 0.6719 acc=60.94%\n",
      "Epoch  28 [  11/  59] loss= 0.6648 acc=63.28%\n",
      "Epoch  28 [  16/  59] loss= 0.6902 acc=54.69%\n",
      "Epoch  28 [  21/  59] loss= 0.6943 acc=53.12%\n",
      "Epoch  28 [  26/  59] loss= 0.6875 acc=55.47%\n",
      "Epoch  28 [  31/  59] loss= 0.6645 acc=64.06%\n",
      "Epoch  28 [  36/  59] loss= 0.6658 acc=63.28%\n",
      "Epoch  28 [  41/  59] loss= 0.6629 acc=64.06%\n",
      "Epoch  28 [  46/  59] loss= 0.6786 acc=58.59%\n",
      "Epoch  28 [  51/  59] loss= 0.6716 acc=60.94%\n",
      "Epoch  28 [  56/  59] loss= 0.6924 acc=53.91%\n",
      "*** Epoch  28 TRAINING loss= 0.6834 acc=57.03% VALIDATION loss= 0.6822 acc=57.38% ***\n",
      "\n",
      "Epoch  29 [   1/  59] loss= 0.6698 acc=61.72%\n",
      "Epoch  29 [   6/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  29 [  11/  59] loss= 0.6920 acc=53.91%\n",
      "Epoch  29 [  16/  59] loss= 0.7048 acc=49.22%\n",
      "Epoch  29 [  21/  59] loss= 0.6916 acc=53.91%\n",
      "Epoch  29 [  26/  59] loss= 0.6978 acc=51.56%\n",
      "Epoch  29 [  31/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  29 [  36/  59] loss= 0.6896 acc=54.69%\n",
      "Epoch  29 [  41/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  29 [  46/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  29 [  51/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  29 [  56/  59] loss= 0.6874 acc=55.47%\n",
      "*** Epoch  29 TRAINING loss= 0.6835 acc=56.97% VALIDATION loss= 0.6603 acc=65.57% ***\n",
      "\n",
      "Epoch  30 [   1/  59] loss= 0.6896 acc=54.69%\n",
      "Epoch  30 [   6/  59] loss= 0.6744 acc=60.16%\n",
      "Epoch  30 [  11/  59] loss= 0.6765 acc=59.38%\n",
      "Epoch  30 [  16/  59] loss= 0.6544 acc=67.19%\n",
      "Epoch  30 [  21/  59] loss= 0.6990 acc=51.56%\n",
      "Epoch  30 [  26/  59] loss= 0.6921 acc=53.91%\n",
      "Epoch  30 [  31/  59] loss= 0.6721 acc=60.94%\n",
      "Epoch  30 [  36/  59] loss= 0.6789 acc=58.59%\n",
      "Epoch  30 [  41/  59] loss= 0.6661 acc=63.28%\n",
      "Epoch  30 [  46/  59] loss= 0.6943 acc=53.12%\n",
      "Epoch  30 [  51/  59] loss= 0.6766 acc=59.38%\n",
      "Epoch  30 [  56/  59] loss= 0.6922 acc=53.91%\n",
      "*** Epoch  30 TRAINING loss= 0.6834 acc=56.99% VALIDATION loss= 0.6680 acc=62.30% ***\n",
      "\n",
      "Epoch  31 [   1/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  31 [   6/  59] loss= 0.6921 acc=53.91%\n",
      "Epoch  31 [  11/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  31 [  16/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  31 [  21/  59] loss= 0.6790 acc=58.59%\n",
      "Epoch  31 [  26/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  31 [  31/  59] loss= 0.6936 acc=53.12%\n",
      "Epoch  31 [  36/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  31 [  41/  59] loss= 0.6752 acc=60.16%\n",
      "Epoch  31 [  46/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  31 [  51/  59] loss= 0.6897 acc=54.69%\n",
      "Epoch  31 [  56/  59] loss= 0.6721 acc=60.94%\n",
      "*** Epoch  31 TRAINING loss= 0.6833 acc=57.03% VALIDATION loss= 0.6822 acc=57.38% ***\n",
      "\n",
      "Epoch  32 [   1/  59] loss= 0.6648 acc=63.28%\n",
      "Epoch  32 [   6/  59] loss= 0.6613 acc=64.06%\n",
      "Epoch  32 [  11/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  32 [  16/  59] loss= 0.6996 acc=52.34%\n",
      "Epoch  32 [  21/  59] loss= 0.6889 acc=55.47%\n",
      "Epoch  32 [  26/  59] loss= 0.6682 acc=61.72%\n",
      "Epoch  32 [  31/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  32 [  36/  59] loss= 0.6994 acc=51.56%\n",
      "Epoch  32 [  41/  59] loss= 0.6747 acc=60.16%\n",
      "Epoch  32 [  46/  59] loss= 0.6792 acc=58.59%\n",
      "Epoch  32 [  51/  59] loss= 0.6667 acc=63.28%\n",
      "Epoch  32 [  56/  59] loss= 0.6853 acc=56.25%\n",
      "*** Epoch  32 TRAINING loss= 0.6832 acc=57.12% VALIDATION loss= 0.7133 acc=45.90% ***\n",
      "\n",
      "Epoch  33 [   1/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  33 [   6/  59] loss= 0.6790 acc=58.59%\n",
      "Epoch  33 [  11/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  33 [  16/  59] loss= 0.7023 acc=50.00%\n",
      "Epoch  33 [  21/  59] loss= 0.6960 acc=52.34%\n",
      "Epoch  33 [  26/  59] loss= 0.6790 acc=58.59%\n",
      "Epoch  33 [  31/  59] loss= 0.6620 acc=64.84%\n",
      "Epoch  33 [  36/  59] loss= 0.6745 acc=60.16%\n",
      "Epoch  33 [  41/  59] loss= 0.6920 acc=53.91%\n",
      "Epoch  33 [  46/  59] loss= 0.6765 acc=59.38%\n",
      "Epoch  33 [  51/  59] loss= 0.7041 acc=50.00%\n",
      "Epoch  33 [  56/  59] loss= 0.6949 acc=53.12%\n",
      "*** Epoch  33 TRAINING loss= 0.6833 acc=57.00% VALIDATION loss= 0.6725 acc=60.66% ***\n",
      "\n",
      "Epoch  34 [   1/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  34 [   6/  59] loss= 0.6944 acc=53.12%\n",
      "Epoch  34 [  11/  59] loss= 0.7011 acc=50.78%\n",
      "Epoch  34 [  16/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  34 [  21/  59] loss= 0.6900 acc=54.69%\n",
      "Epoch  34 [  26/  59] loss= 0.6721 acc=60.94%\n",
      "Epoch  34 [  31/  59] loss= 0.6921 acc=53.91%\n",
      "Epoch  34 [  36/  59] loss= 0.7045 acc=49.22%\n",
      "Epoch  34 [  41/  59] loss= 0.6752 acc=60.16%\n",
      "Epoch  34 [  46/  59] loss= 0.6712 acc=61.72%\n",
      "Epoch  34 [  51/  59] loss= 0.6770 acc=59.38%\n",
      "Epoch  34 [  56/  59] loss= 0.6876 acc=55.47%\n",
      "*** Epoch  34 TRAINING loss= 0.6831 acc=57.12% VALIDATION loss= 0.7155 acc=45.90% ***\n",
      "\n",
      "Epoch  35 [   1/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  35 [   6/  59] loss= 0.6739 acc=60.16%\n",
      "Epoch  35 [  11/  59] loss= 0.7167 acc=46.09%\n",
      "Epoch  35 [  16/  59] loss= 0.7132 acc=46.88%\n",
      "Epoch  35 [  21/  59] loss= 0.7069 acc=48.44%\n",
      "Epoch  35 [  26/  59] loss= 0.6794 acc=58.59%\n",
      "Epoch  35 [  31/  59] loss= 0.6703 acc=62.50%\n",
      "Epoch  35 [  36/  59] loss= 0.6892 acc=54.69%\n",
      "Epoch  35 [  41/  59] loss= 0.6873 acc=55.47%\n",
      "Epoch  35 [  46/  59] loss= 0.6957 acc=52.34%\n",
      "Epoch  35 [  51/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  35 [  56/  59] loss= 0.6604 acc=64.84%\n",
      "*** Epoch  35 TRAINING loss= 0.6837 acc=56.94% VALIDATION loss= 0.6469 acc=68.85% ***\n",
      "\n",
      "Epoch  36 [   1/  59] loss= 0.6665 acc=62.50%\n",
      "Epoch  36 [   6/  59] loss= 0.6609 acc=64.06%\n",
      "Epoch  36 [  11/  59] loss= 0.7263 acc=43.75%\n",
      "Epoch  36 [  16/  59] loss= 0.7025 acc=50.78%\n",
      "Epoch  36 [  21/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  36 [  26/  59] loss= 0.6875 acc=55.47%\n",
      "Epoch  36 [  31/  59] loss= 0.6734 acc=60.94%\n",
      "Epoch  36 [  36/  59] loss= 0.6528 acc=69.53%\n",
      "Epoch  36 [  41/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  36 [  46/  59] loss= 0.6722 acc=61.72%\n",
      "Epoch  36 [  51/  59] loss= 0.6576 acc=67.19%\n",
      "Epoch  36 [  56/  59] loss= 0.6599 acc=65.62%\n",
      "*** Epoch  36 TRAINING loss= 0.6837 acc=56.98% VALIDATION loss= 0.6632 acc=63.93% ***\n",
      "\n",
      "Epoch  37 [   1/  59] loss= 0.7127 acc=46.88%\n",
      "Epoch  37 [   6/  59] loss= 0.6903 acc=54.69%\n",
      "Epoch  37 [  11/  59] loss= 0.6949 acc=53.12%\n",
      "Epoch  37 [  16/  59] loss= 0.6765 acc=59.38%\n",
      "Epoch  37 [  21/  59] loss= 0.6700 acc=61.72%\n",
      "Epoch  37 [  26/  59] loss= 0.6679 acc=62.50%\n",
      "Epoch  37 [  31/  59] loss= 0.6763 acc=59.38%\n",
      "Epoch  37 [  36/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  37 [  41/  59] loss= 0.7008 acc=51.56%\n",
      "Epoch  37 [  46/  59] loss= 0.6618 acc=64.06%\n",
      "Epoch  37 [  51/  59] loss= 0.6714 acc=60.94%\n",
      "Epoch  37 [  56/  59] loss= 0.6572 acc=65.62%\n",
      "*** Epoch  37 TRAINING loss= 0.6834 acc=57.03% VALIDATION loss= 0.6822 acc=57.38% ***\n",
      "\n",
      "Epoch  38 [   1/  59] loss= 0.6785 acc=58.59%\n",
      "Epoch  38 [   6/  59] loss= 0.6905 acc=54.69%\n",
      "Epoch  38 [  11/  59] loss= 0.6739 acc=60.16%\n",
      "Epoch  38 [  16/  59] loss= 0.6787 acc=58.59%\n",
      "Epoch  38 [  21/  59] loss= 0.6700 acc=61.72%\n",
      "Epoch  38 [  26/  59] loss= 0.6986 acc=51.56%\n",
      "Epoch  38 [  31/  59] loss= 0.6790 acc=58.59%\n",
      "Epoch  38 [  36/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  38 [  41/  59] loss= 0.6812 acc=57.81%\n",
      "Epoch  38 [  46/  59] loss= 0.6753 acc=60.16%\n",
      "Epoch  38 [  51/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  38 [  56/  59] loss= 0.6709 acc=61.72%\n",
      "*** Epoch  38 TRAINING loss= 0.6833 acc=57.03% VALIDATION loss= 0.6823 acc=57.38% ***\n",
      "\n",
      "Epoch  39 [   1/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  39 [   6/  59] loss= 0.6763 acc=59.38%\n",
      "Epoch  39 [  11/  59] loss= 0.6904 acc=54.69%\n",
      "Epoch  39 [  16/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  39 [  21/  59] loss= 0.6946 acc=53.12%\n",
      "Epoch  39 [  26/  59] loss= 0.6701 acc=61.72%\n",
      "Epoch  39 [  31/  59] loss= 0.6986 acc=51.56%\n",
      "Epoch  39 [  36/  59] loss= 0.6810 acc=57.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  39 [  41/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  39 [  46/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  39 [  51/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  39 [  56/  59] loss= 0.6902 acc=54.69%\n",
      "*** Epoch  39 TRAINING loss= 0.6834 acc=57.03% VALIDATION loss= 0.6822 acc=57.38% ***\n",
      "\n",
      "Epoch  40 [   1/  59] loss= 0.6787 acc=58.59%\n",
      "Epoch  40 [   6/  59] loss= 0.6746 acc=60.16%\n",
      "Epoch  40 [  11/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  40 [  16/  59] loss= 0.6672 acc=63.28%\n",
      "Epoch  40 [  21/  59] loss= 0.6773 acc=59.38%\n",
      "Epoch  40 [  26/  59] loss= 0.6770 acc=59.38%\n",
      "Epoch  40 [  31/  59] loss= 0.6876 acc=55.47%\n",
      "Epoch  40 [  36/  59] loss= 0.6721 acc=60.94%\n",
      "Epoch  40 [  41/  59] loss= 0.6626 acc=64.06%\n",
      "Epoch  40 [  46/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  40 [  51/  59] loss= 0.6737 acc=60.16%\n",
      "Epoch  40 [  56/  59] loss= 0.6785 acc=58.59%\n",
      "*** Epoch  40 TRAINING loss= 0.6832 acc=57.08% VALIDATION loss= 0.7019 acc=50.82% ***\n",
      "\n",
      "Epoch  41 [   1/  59] loss= 0.6762 acc=59.38%\n",
      "Epoch  41 [   6/  59] loss= 0.6786 acc=58.59%\n",
      "Epoch  41 [  11/  59] loss= 0.6697 acc=61.72%\n",
      "Epoch  41 [  16/  59] loss= 0.6696 acc=61.72%\n",
      "Epoch  41 [  21/  59] loss= 0.6878 acc=55.47%\n",
      "Epoch  41 [  26/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  41 [  31/  59] loss= 0.6694 acc=61.72%\n",
      "Epoch  41 [  36/  59] loss= 0.7040 acc=50.00%\n",
      "Epoch  41 [  41/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  41 [  46/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  41 [  51/  59] loss= 0.6979 acc=51.56%\n",
      "Epoch  41 [  56/  59] loss= 0.6771 acc=59.38%\n",
      "*** Epoch  41 TRAINING loss= 0.6832 acc=57.07% VALIDATION loss= 0.6955 acc=52.46% ***\n",
      "\n",
      "Epoch  42 [   1/  59] loss= 0.6728 acc=60.94%\n",
      "Epoch  42 [   6/  59] loss= 0.6725 acc=60.94%\n",
      "Epoch  42 [  11/  59] loss= 0.6721 acc=60.94%\n",
      "Epoch  42 [  16/  59] loss= 0.6717 acc=60.94%\n",
      "Epoch  42 [  21/  59] loss= 0.6646 acc=63.28%\n",
      "Epoch  42 [  26/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  42 [  31/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  42 [  36/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  42 [  41/  59] loss= 0.6585 acc=64.84%\n",
      "Epoch  42 [  46/  59] loss= 0.6936 acc=53.91%\n",
      "Epoch  42 [  51/  59] loss= 0.6857 acc=56.25%\n",
      "Epoch  42 [  56/  59] loss= 0.6855 acc=56.25%\n",
      "*** Epoch  42 TRAINING loss= 0.6833 acc=57.06% VALIDATION loss= 0.6911 acc=54.10% ***\n",
      "\n",
      "Epoch  43 [   1/  59] loss= 0.6916 acc=53.91%\n",
      "Epoch  43 [   6/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  43 [  11/  59] loss= 0.6795 acc=58.59%\n",
      "Epoch  43 [  16/  59] loss= 0.6815 acc=57.81%\n",
      "Epoch  43 [  21/  59] loss= 0.6774 acc=59.38%\n",
      "Epoch  43 [  26/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  43 [  31/  59] loss= 0.7015 acc=50.78%\n",
      "Epoch  43 [  36/  59] loss= 0.7042 acc=50.00%\n",
      "Epoch  43 [  41/  59] loss= 0.6742 acc=60.16%\n",
      "Epoch  43 [  46/  59] loss= 0.6919 acc=53.91%\n",
      "Epoch  43 [  51/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  43 [  56/  59] loss= 0.6727 acc=60.94%\n",
      "*** Epoch  43 TRAINING loss= 0.6836 acc=56.98% VALIDATION loss= 0.6645 acc=63.93% ***\n",
      "\n",
      "Epoch  44 [   1/  59] loss= 0.6620 acc=64.84%\n",
      "Epoch  44 [   6/  59] loss= 0.7099 acc=47.66%\n",
      "Epoch  44 [  11/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  44 [  16/  59] loss= 0.6942 acc=53.12%\n",
      "Epoch  44 [  21/  59] loss= 0.6591 acc=65.62%\n",
      "Epoch  44 [  26/  59] loss= 0.6878 acc=55.47%\n",
      "Epoch  44 [  31/  59] loss= 0.6926 acc=53.91%\n",
      "Epoch  44 [  36/  59] loss= 0.6761 acc=59.38%\n",
      "Epoch  44 [  41/  59] loss= 0.7092 acc=48.44%\n",
      "Epoch  44 [  46/  59] loss= 0.6764 acc=59.38%\n",
      "Epoch  44 [  51/  59] loss= 0.6653 acc=63.28%\n",
      "Epoch  44 [  56/  59] loss= 0.7097 acc=47.66%\n",
      "*** Epoch  44 TRAINING loss= 0.6834 acc=57.02% VALIDATION loss= 0.6778 acc=59.02% ***\n",
      "\n",
      "Epoch  45 [   1/  59] loss= 0.6896 acc=54.69%\n",
      "Epoch  45 [   6/  59] loss= 0.6710 acc=61.72%\n",
      "Epoch  45 [  11/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  45 [  16/  59] loss= 0.6592 acc=65.62%\n",
      "Epoch  45 [  21/  59] loss= 0.6788 acc=58.59%\n",
      "Epoch  45 [  26/  59] loss= 0.6921 acc=53.91%\n",
      "Epoch  45 [  31/  59] loss= 0.6898 acc=54.69%\n",
      "Epoch  45 [  36/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  45 [  41/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  45 [  46/  59] loss= 0.6790 acc=58.59%\n",
      "Epoch  45 [  51/  59] loss= 0.7136 acc=46.09%\n",
      "Epoch  45 [  56/  59] loss= 0.6854 acc=56.25%\n",
      "*** Epoch  45 TRAINING loss= 0.6835 acc=56.98% VALIDATION loss= 0.6645 acc=63.93% ***\n",
      "\n",
      "Epoch  46 [   1/  59] loss= 0.6875 acc=55.47%\n",
      "Epoch  46 [   6/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  46 [  11/  59] loss= 0.6710 acc=61.72%\n",
      "Epoch  46 [  16/  59] loss= 0.6896 acc=54.69%\n",
      "Epoch  46 [  21/  59] loss= 0.6649 acc=64.06%\n",
      "Epoch  46 [  26/  59] loss= 0.7092 acc=46.88%\n",
      "Epoch  46 [  31/  59] loss= 0.6742 acc=60.94%\n",
      "Epoch  46 [  36/  59] loss= 0.6798 acc=58.59%\n",
      "Epoch  46 [  41/  59] loss= 0.6794 acc=58.59%\n",
      "Epoch  46 [  46/  59] loss= 0.6766 acc=59.38%\n",
      "Epoch  46 [  51/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  46 [  56/  59] loss= 0.6809 acc=57.81%\n",
      "*** Epoch  46 TRAINING loss= 0.6832 acc=57.14% VALIDATION loss= 0.7252 acc=44.26% ***\n",
      "\n",
      "Epoch  47 [   1/  59] loss= 0.6886 acc=55.47%\n",
      "Epoch  47 [   6/  59] loss= 0.6885 acc=55.47%\n",
      "Epoch  47 [  11/  59] loss= 0.6784 acc=58.59%\n",
      "Epoch  47 [  16/  59] loss= 0.6610 acc=64.06%\n",
      "Epoch  47 [  21/  59] loss= 0.6958 acc=53.12%\n",
      "Epoch  47 [  26/  59] loss= 0.6859 acc=56.25%\n",
      "Epoch  47 [  31/  59] loss= 0.7038 acc=50.78%\n",
      "Epoch  47 [  36/  59] loss= 0.6857 acc=56.25%\n",
      "Epoch  47 [  41/  59] loss= 0.7083 acc=48.44%\n",
      "Epoch  47 [  46/  59] loss= 0.6790 acc=58.59%\n",
      "Epoch  47 [  51/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  47 [  56/  59] loss= 0.6916 acc=53.91%\n",
      "*** Epoch  47 TRAINING loss= 0.6833 acc=57.07% VALIDATION loss= 0.6955 acc=52.46% ***\n",
      "\n",
      "Epoch  48 [   1/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  48 [   6/  59] loss= 0.6981 acc=51.56%\n",
      "Epoch  48 [  11/  59] loss= 0.6788 acc=58.59%\n",
      "Epoch  48 [  16/  59] loss= 0.6669 acc=62.50%\n",
      "Epoch  48 [  21/  59] loss= 0.6737 acc=60.16%\n",
      "Epoch  48 [  26/  59] loss= 0.7139 acc=46.88%\n",
      "Epoch  48 [  31/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  48 [  36/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  48 [  41/  59] loss= 0.6789 acc=58.59%\n",
      "Epoch  48 [  46/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  48 [  51/  59] loss= 0.6917 acc=53.91%\n",
      "Epoch  48 [  56/  59] loss= 0.6895 acc=54.69%\n",
      "*** Epoch  48 TRAINING loss= 0.6835 acc=56.99% VALIDATION loss= 0.6694 acc=62.30% ***\n",
      "\n",
      "Epoch  49 [   1/  59] loss= 0.6750 acc=60.16%\n",
      "Epoch  49 [   6/  59] loss= 0.6666 acc=63.28%\n",
      "Epoch  49 [  11/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  49 [  16/  59] loss= 0.6919 acc=53.91%\n",
      "Epoch  49 [  21/  59] loss= 0.6768 acc=59.38%\n",
      "Epoch  49 [  26/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  49 [  31/  59] loss= 0.6979 acc=51.56%\n",
      "Epoch  49 [  36/  59] loss= 0.6712 acc=61.72%\n",
      "Epoch  49 [  41/  59] loss= 0.6894 acc=54.69%\n",
      "Epoch  49 [  46/  59] loss= 0.6731 acc=60.94%\n",
      "Epoch  49 [  51/  59] loss= 0.6749 acc=60.16%\n",
      "Epoch  49 [  56/  59] loss= 0.6636 acc=64.06%\n",
      "*** Epoch  49 TRAINING loss= 0.6834 acc=57.02% VALIDATION loss= 0.6775 acc=59.02% ***\n",
      "\n",
      "Epoch  50 [   1/  59] loss= 0.6968 acc=52.34%\n",
      "Epoch  50 [   6/  59] loss= 0.6903 acc=54.69%\n",
      "Epoch  50 [  11/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  50 [  16/  59] loss= 0.6934 acc=53.91%\n",
      "Epoch  50 [  21/  59] loss= 0.6860 acc=56.25%\n",
      "Epoch  50 [  26/  59] loss= 0.6834 acc=57.03%\n",
      "Epoch  50 [  31/  59] loss= 0.7074 acc=49.22%\n",
      "Epoch  50 [  36/  59] loss= 0.6994 acc=51.56%\n",
      "Epoch  50 [  41/  59] loss= 0.6945 acc=53.12%\n",
      "Epoch  50 [  46/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  50 [  51/  59] loss= 0.6542 acc=67.97%\n",
      "Epoch  50 [  56/  59] loss= 0.6770 acc=59.38%\n",
      "*** Epoch  50 TRAINING loss= 0.6831 acc=57.11% VALIDATION loss= 0.7087 acc=47.54% ***\n",
      "\n",
      "Epoch  51 [   1/  59] loss= 0.6665 acc=63.28%\n",
      "Epoch  51 [   6/  59] loss= 0.6875 acc=55.47%\n",
      "Epoch  51 [  11/  59] loss= 0.6704 acc=61.72%\n",
      "Epoch  51 [  16/  59] loss= 0.6720 acc=60.94%\n",
      "Epoch  51 [  21/  59] loss= 0.6718 acc=60.94%\n",
      "Epoch  51 [  26/  59] loss= 0.6969 acc=52.34%\n",
      "Epoch  51 [  31/  59] loss= 0.6787 acc=58.59%\n",
      "Epoch  51 [  36/  59] loss= 0.6970 acc=52.34%\n",
      "Epoch  51 [  41/  59] loss= 0.6920 acc=53.91%\n",
      "Epoch  51 [  46/  59] loss= 0.6732 acc=60.94%\n",
      "Epoch  51 [  51/  59] loss= 0.6737 acc=60.94%\n",
      "Epoch  51 [  56/  59] loss= 0.6873 acc=55.47%\n",
      "*** Epoch  51 TRAINING loss= 0.6834 acc=57.03% VALIDATION loss= 0.6824 acc=57.38% ***\n",
      "\n",
      "Epoch  52 [   1/  59] loss= 0.6914 acc=53.91%\n",
      "Epoch  52 [   6/  59] loss= 0.6723 acc=60.94%\n",
      "Epoch  52 [  11/  59] loss= 0.6927 acc=53.91%\n",
      "Epoch  52 [  16/  59] loss= 0.6624 acc=64.06%\n",
      "Epoch  52 [  21/  59] loss= 0.6696 acc=61.72%\n",
      "Epoch  52 [  26/  59] loss= 0.7012 acc=50.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  52 [  31/  59] loss= 0.6698 acc=61.72%\n",
      "Epoch  52 [  36/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  52 [  41/  59] loss= 0.6628 acc=64.06%\n",
      "Epoch  52 [  46/  59] loss= 0.7064 acc=49.22%\n",
      "Epoch  52 [  51/  59] loss= 0.6901 acc=54.69%\n",
      "Epoch  52 [  56/  59] loss= 0.6743 acc=60.16%\n",
      "*** Epoch  52 TRAINING loss= 0.6832 acc=57.10% VALIDATION loss= 0.7057 acc=49.18% ***\n",
      "\n",
      "Epoch  53 [   1/  59] loss= 0.6989 acc=51.56%\n",
      "Epoch  53 [   6/  59] loss= 0.6900 acc=54.69%\n",
      "Epoch  53 [  11/  59] loss= 0.6764 acc=59.38%\n",
      "Epoch  53 [  16/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  53 [  21/  59] loss= 0.6787 acc=58.59%\n",
      "Epoch  53 [  26/  59] loss= 0.6968 acc=52.34%\n",
      "Epoch  53 [  31/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  53 [  36/  59] loss= 0.6676 acc=62.50%\n",
      "Epoch  53 [  41/  59] loss= 0.6764 acc=59.38%\n",
      "Epoch  53 [  46/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  53 [  51/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  53 [  56/  59] loss= 0.6752 acc=60.16%\n",
      "*** Epoch  53 TRAINING loss= 0.6832 acc=57.07% VALIDATION loss= 0.6954 acc=52.46% ***\n",
      "\n",
      "Epoch  54 [   1/  59] loss= 0.6812 acc=57.81%\n",
      "Epoch  54 [   6/  59] loss= 0.6684 acc=62.50%\n",
      "Epoch  54 [  11/  59] loss= 0.6725 acc=60.94%\n",
      "Epoch  54 [  16/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  54 [  21/  59] loss= 0.6720 acc=60.94%\n",
      "Epoch  54 [  26/  59] loss= 0.6648 acc=63.28%\n",
      "Epoch  54 [  31/  59] loss= 0.6736 acc=60.16%\n",
      "Epoch  54 [  36/  59] loss= 0.6958 acc=53.12%\n",
      "Epoch  54 [  41/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  54 [  46/  59] loss= 0.6900 acc=54.69%\n",
      "Epoch  54 [  51/  59] loss= 0.7025 acc=50.00%\n",
      "Epoch  54 [  56/  59] loss= 0.6554 acc=67.97%\n",
      "*** Epoch  54 TRAINING loss= 0.6833 acc=57.10% VALIDATION loss= 0.7037 acc=49.18% ***\n",
      "\n",
      "Epoch  55 [   1/  59] loss= 0.6752 acc=60.16%\n",
      "Epoch  55 [   6/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  55 [  11/  59] loss= 0.6961 acc=52.34%\n",
      "Epoch  55 [  16/  59] loss= 0.6687 acc=62.50%\n",
      "Epoch  55 [  21/  59] loss= 0.6664 acc=63.28%\n",
      "Epoch  55 [  26/  59] loss= 0.6720 acc=60.94%\n",
      "Epoch  55 [  31/  59] loss= 0.6902 acc=54.69%\n",
      "Epoch  55 [  36/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  55 [  41/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  55 [  46/  59] loss= 0.6879 acc=55.47%\n",
      "Epoch  55 [  51/  59] loss= 0.7123 acc=46.88%\n",
      "Epoch  55 [  56/  59] loss= 0.6898 acc=54.69%\n",
      "*** Epoch  55 TRAINING loss= 0.6834 acc=57.00% VALIDATION loss= 0.6731 acc=60.66% ***\n",
      "\n",
      "Epoch  56 [   1/  59] loss= 0.6570 acc=66.41%\n",
      "Epoch  56 [   6/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  56 [  11/  59] loss= 0.6612 acc=64.84%\n",
      "Epoch  56 [  16/  59] loss= 0.6898 acc=54.69%\n",
      "Epoch  56 [  21/  59] loss= 0.6744 acc=60.16%\n",
      "Epoch  56 [  26/  59] loss= 0.6924 acc=53.91%\n",
      "Epoch  56 [  31/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  56 [  36/  59] loss= 0.6903 acc=54.69%\n",
      "Epoch  56 [  41/  59] loss= 0.6738 acc=60.16%\n",
      "Epoch  56 [  46/  59] loss= 0.6928 acc=53.91%\n",
      "Epoch  56 [  51/  59] loss= 0.6949 acc=53.12%\n",
      "Epoch  56 [  56/  59] loss= 0.6876 acc=55.47%\n",
      "*** Epoch  56 TRAINING loss= 0.6833 acc=57.04% VALIDATION loss= 0.6867 acc=55.74% ***\n",
      "\n",
      "Epoch  57 [   1/  59] loss= 0.6917 acc=53.91%\n",
      "Epoch  57 [   6/  59] loss= 0.6915 acc=53.91%\n",
      "Epoch  57 [  11/  59] loss= 0.6794 acc=58.59%\n",
      "Epoch  57 [  16/  59] loss= 0.7025 acc=49.22%\n",
      "Epoch  57 [  21/  59] loss= 0.6798 acc=58.59%\n",
      "Epoch  57 [  26/  59] loss= 0.6781 acc=59.38%\n",
      "Epoch  57 [  31/  59] loss= 0.6690 acc=63.28%\n",
      "Epoch  57 [  36/  59] loss= 0.6758 acc=60.16%\n",
      "Epoch  57 [  41/  59] loss= 0.6894 acc=54.69%\n",
      "Epoch  57 [  46/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  57 [  51/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  57 [  56/  59] loss= 0.6809 acc=57.81%\n",
      "*** Epoch  57 TRAINING loss= 0.6832 acc=57.04% VALIDATION loss= 0.6874 acc=55.74% ***\n",
      "\n",
      "Epoch  58 [   1/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  58 [   6/  59] loss= 0.6784 acc=58.59%\n",
      "Epoch  58 [  11/  59] loss= 0.6882 acc=55.47%\n",
      "Epoch  58 [  16/  59] loss= 0.6715 acc=60.94%\n",
      "Epoch  58 [  21/  59] loss= 0.6786 acc=58.59%\n",
      "Epoch  58 [  26/  59] loss= 0.6672 acc=62.50%\n",
      "Epoch  58 [  31/  59] loss= 0.6877 acc=55.47%\n",
      "Epoch  58 [  36/  59] loss= 0.6768 acc=59.38%\n",
      "Epoch  58 [  41/  59] loss= 0.6768 acc=59.38%\n",
      "Epoch  58 [  46/  59] loss= 0.6988 acc=51.56%\n",
      "Epoch  58 [  51/  59] loss= 0.6658 acc=63.28%\n",
      "Epoch  58 [  56/  59] loss= 0.6832 acc=57.03%\n",
      "*** Epoch  58 TRAINING loss= 0.6834 acc=57.02% VALIDATION loss= 0.6774 acc=59.02% ***\n",
      "\n",
      "Epoch  59 [   1/  59] loss= 0.6878 acc=55.47%\n",
      "Epoch  59 [   6/  59] loss= 0.6971 acc=52.34%\n",
      "Epoch  59 [  11/  59] loss= 0.6785 acc=58.59%\n",
      "Epoch  59 [  16/  59] loss= 0.6597 acc=64.84%\n",
      "Epoch  59 [  21/  59] loss= 0.7134 acc=46.88%\n",
      "Epoch  59 [  26/  59] loss= 0.7071 acc=48.44%\n",
      "Epoch  59 [  31/  59] loss= 0.6873 acc=55.47%\n",
      "Epoch  59 [  36/  59] loss= 0.6695 acc=62.50%\n",
      "Epoch  59 [  41/  59] loss= 0.6792 acc=58.59%\n",
      "Epoch  59 [  46/  59] loss= 0.6748 acc=60.16%\n",
      "Epoch  59 [  51/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  59 [  56/  59] loss= 0.6740 acc=60.16%\n",
      "*** Epoch  59 TRAINING loss= 0.6835 acc=57.02% VALIDATION loss= 0.6773 acc=59.02% ***\n",
      "\n",
      "Epoch  60 [   1/  59] loss= 0.6786 acc=58.59%\n",
      "Epoch  60 [   6/  59] loss= 0.6671 acc=62.50%\n",
      "Epoch  60 [  11/  59] loss= 0.6924 acc=53.91%\n",
      "Epoch  60 [  16/  59] loss= 0.6608 acc=64.84%\n",
      "Epoch  60 [  21/  59] loss= 0.6924 acc=53.91%\n",
      "Epoch  60 [  26/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  60 [  31/  59] loss= 0.6964 acc=52.34%\n",
      "Epoch  60 [  36/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  60 [  41/  59] loss= 0.6873 acc=55.47%\n",
      "Epoch  60 [  46/  59] loss= 0.6708 acc=61.72%\n",
      "Epoch  60 [  51/  59] loss= 0.6876 acc=55.47%\n",
      "Epoch  60 [  56/  59] loss= 0.6766 acc=59.38%\n",
      "*** Epoch  60 TRAINING loss= 0.6832 acc=57.08% VALIDATION loss= 0.7011 acc=50.82% ***\n",
      "\n",
      "Epoch  61 [   1/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  61 [   6/  59] loss= 0.6608 acc=64.84%\n",
      "Epoch  61 [  11/  59] loss= 0.6694 acc=61.72%\n",
      "Epoch  61 [  16/  59] loss= 0.7027 acc=50.78%\n",
      "Epoch  61 [  21/  59] loss= 0.6880 acc=55.47%\n",
      "Epoch  61 [  26/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  61 [  31/  59] loss= 0.6761 acc=59.38%\n",
      "Epoch  61 [  36/  59] loss= 0.6710 acc=60.94%\n",
      "Epoch  61 [  41/  59] loss= 0.6759 acc=59.38%\n",
      "Epoch  61 [  46/  59] loss= 0.7009 acc=51.56%\n",
      "Epoch  61 [  51/  59] loss= 0.6976 acc=52.34%\n",
      "Epoch  61 [  56/  59] loss= 0.6855 acc=56.25%\n",
      "*** Epoch  61 TRAINING loss= 0.6834 acc=57.02% VALIDATION loss= 0.6778 acc=59.02% ***\n",
      "\n",
      "Epoch  62 [   1/  59] loss= 0.6747 acc=60.16%\n",
      "Epoch  62 [   6/  59] loss= 0.6895 acc=54.69%\n",
      "Epoch  62 [  11/  59] loss= 0.6685 acc=62.50%\n",
      "Epoch  62 [  16/  59] loss= 0.6897 acc=54.69%\n",
      "Epoch  62 [  21/  59] loss= 0.6746 acc=60.16%\n",
      "Epoch  62 [  26/  59] loss= 0.6682 acc=62.50%\n",
      "Epoch  62 [  31/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  62 [  36/  59] loss= 0.7080 acc=47.66%\n",
      "Epoch  62 [  41/  59] loss= 0.6779 acc=59.38%\n",
      "Epoch  62 [  46/  59] loss= 0.6746 acc=60.94%\n",
      "Epoch  62 [  51/  59] loss= 0.6592 acc=67.19%\n",
      "Epoch  62 [  56/  59] loss= 0.6813 acc=57.81%\n",
      "*** Epoch  62 TRAINING loss= 0.6834 acc=57.06% VALIDATION loss= 0.6913 acc=54.10% ***\n",
      "\n",
      "Epoch  63 [   1/  59] loss= 0.6919 acc=53.91%\n",
      "Epoch  63 [   6/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  63 [  11/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  63 [  16/  59] loss= 0.6978 acc=52.34%\n",
      "Epoch  63 [  21/  59] loss= 0.6931 acc=53.91%\n",
      "Epoch  63 [  26/  59] loss= 0.6906 acc=54.69%\n",
      "Epoch  63 [  31/  59] loss= 0.6686 acc=61.72%\n",
      "Epoch  63 [  36/  59] loss= 0.6784 acc=58.59%\n",
      "Epoch  63 [  41/  59] loss= 0.6957 acc=53.12%\n",
      "Epoch  63 [  46/  59] loss= 0.6625 acc=64.06%\n",
      "Epoch  63 [  51/  59] loss= 0.6768 acc=59.38%\n",
      "Epoch  63 [  56/  59] loss= 0.6710 acc=61.72%\n",
      "*** Epoch  63 TRAINING loss= 0.6834 acc=57.03% VALIDATION loss= 0.6824 acc=57.38% ***\n",
      "\n",
      "Epoch  64 [   1/  59] loss= 0.6935 acc=53.12%\n",
      "Epoch  64 [   6/  59] loss= 0.6686 acc=62.50%\n",
      "Epoch  64 [  11/  59] loss= 0.6875 acc=55.47%\n",
      "Epoch  64 [  16/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  64 [  21/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  64 [  26/  59] loss= 0.6902 acc=54.69%\n",
      "Epoch  64 [  31/  59] loss= 0.6878 acc=55.47%\n",
      "Epoch  64 [  36/  59] loss= 0.6787 acc=58.59%\n",
      "Epoch  64 [  41/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  64 [  46/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  64 [  51/  59] loss= 0.6665 acc=63.28%\n",
      "Epoch  64 [  56/  59] loss= 0.6746 acc=60.16%\n",
      "*** Epoch  64 TRAINING loss= 0.6836 acc=56.95% VALIDATION loss= 0.6549 acc=67.21% ***\n",
      "\n",
      "Epoch  65 [   1/  59] loss= 0.6984 acc=51.56%\n",
      "Epoch  65 [   6/  59] loss= 0.6917 acc=53.91%\n",
      "Epoch  65 [  11/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  65 [  16/  59] loss= 0.6775 acc=59.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  65 [  21/  59] loss= 0.6772 acc=59.38%\n",
      "Epoch  65 [  26/  59] loss= 0.6771 acc=59.38%\n",
      "Epoch  65 [  31/  59] loss= 0.6689 acc=62.50%\n",
      "Epoch  65 [  36/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  65 [  41/  59] loss= 0.6635 acc=64.06%\n",
      "Epoch  65 [  46/  59] loss= 0.7107 acc=47.66%\n",
      "Epoch  65 [  51/  59] loss= 0.6946 acc=53.12%\n",
      "Epoch  65 [  56/  59] loss= 0.6968 acc=52.34%\n",
      "*** Epoch  65 TRAINING loss= 0.6834 acc=56.99% VALIDATION loss= 0.6680 acc=62.30% ***\n",
      "\n",
      "Epoch  66 [   1/  59] loss= 0.7036 acc=50.00%\n",
      "Epoch  66 [   6/  59] loss= 0.6676 acc=62.50%\n",
      "Epoch  66 [  11/  59] loss= 0.6677 acc=62.50%\n",
      "Epoch  66 [  16/  59] loss= 0.6676 acc=62.50%\n",
      "Epoch  66 [  21/  59] loss= 0.6900 acc=54.69%\n",
      "Epoch  66 [  26/  59] loss= 0.6787 acc=58.59%\n",
      "Epoch  66 [  31/  59] loss= 0.6715 acc=60.94%\n",
      "Epoch  66 [  36/  59] loss= 0.6736 acc=60.16%\n",
      "Epoch  66 [  41/  59] loss= 0.6834 acc=57.03%\n",
      "Epoch  66 [  46/  59] loss= 0.6834 acc=57.03%\n",
      "Epoch  66 [  51/  59] loss= 0.6646 acc=63.28%\n",
      "Epoch  66 [  56/  59] loss= 0.7036 acc=50.00%\n",
      "*** Epoch  66 TRAINING loss= 0.6835 acc=56.98% VALIDATION loss= 0.6642 acc=63.93% ***\n",
      "\n",
      "Epoch  67 [   1/  59] loss= 0.6789 acc=58.59%\n",
      "Epoch  67 [   6/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  67 [  11/  59] loss= 0.6775 acc=59.38%\n",
      "Epoch  67 [  16/  59] loss= 0.6992 acc=50.78%\n",
      "Epoch  67 [  21/  59] loss= 0.6994 acc=50.78%\n",
      "Epoch  67 [  26/  59] loss= 0.7101 acc=46.88%\n",
      "Epoch  67 [  31/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  67 [  36/  59] loss= 0.6747 acc=60.16%\n",
      "Epoch  67 [  41/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  67 [  46/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  67 [  51/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  67 [  56/  59] loss= 0.6854 acc=56.25%\n",
      "*** Epoch  67 TRAINING loss= 0.6834 acc=57.00% VALIDATION loss= 0.6731 acc=60.66% ***\n",
      "\n",
      "Epoch  68 [   1/  59] loss= 0.6745 acc=60.16%\n",
      "Epoch  68 [   6/  59] loss= 0.6764 acc=59.38%\n",
      "Epoch  68 [  11/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  68 [  16/  59] loss= 0.6882 acc=55.47%\n",
      "Epoch  68 [  21/  59] loss= 0.6759 acc=59.38%\n",
      "Epoch  68 [  26/  59] loss= 0.7059 acc=50.00%\n",
      "Epoch  68 [  31/  59] loss= 0.6834 acc=57.03%\n",
      "Epoch  68 [  36/  59] loss= 0.6929 acc=53.91%\n",
      "Epoch  68 [  41/  59] loss= 0.7209 acc=44.53%\n",
      "Epoch  68 [  46/  59] loss= 0.6745 acc=60.16%\n",
      "Epoch  68 [  51/  59] loss= 0.6608 acc=65.62%\n",
      "Epoch  68 [  56/  59] loss= 0.7040 acc=49.22%\n",
      "*** Epoch  68 TRAINING loss= 0.6835 acc=56.97% VALIDATION loss= 0.6606 acc=65.57% ***\n",
      "\n",
      "Epoch  69 [   1/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  69 [   6/  59] loss= 0.6935 acc=53.12%\n",
      "Epoch  69 [  11/  59] loss= 0.6892 acc=54.69%\n",
      "Epoch  69 [  16/  59] loss= 0.7008 acc=50.00%\n",
      "Epoch  69 [  21/  59] loss= 0.6774 acc=59.38%\n",
      "Epoch  69 [  26/  59] loss= 0.6999 acc=50.78%\n",
      "Epoch  69 [  31/  59] loss= 0.6725 acc=60.94%\n",
      "Epoch  69 [  36/  59] loss= 0.6763 acc=59.38%\n",
      "Epoch  69 [  41/  59] loss= 0.6934 acc=53.91%\n",
      "Epoch  69 [  46/  59] loss= 0.6911 acc=54.69%\n",
      "Epoch  69 [  51/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  69 [  56/  59] loss= 0.6833 acc=57.03%\n",
      "*** Epoch  69 TRAINING loss= 0.6834 acc=57.07% VALIDATION loss= 0.6963 acc=52.46% ***\n",
      "\n",
      "Epoch  70 [   1/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  70 [   6/  59] loss= 0.6987 acc=51.56%\n",
      "Epoch  70 [  11/  59] loss= 0.6876 acc=55.47%\n",
      "Epoch  70 [  16/  59] loss= 0.6508 acc=68.75%\n",
      "Epoch  70 [  21/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  70 [  26/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  70 [  31/  59] loss= 0.6943 acc=53.12%\n",
      "Epoch  70 [  36/  59] loss= 0.6791 acc=58.59%\n",
      "Epoch  70 [  41/  59] loss= 0.6894 acc=54.69%\n",
      "Epoch  70 [  46/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  70 [  51/  59] loss= 0.6729 acc=60.94%\n",
      "Epoch  70 [  56/  59] loss= 0.7207 acc=43.75%\n",
      "*** Epoch  70 TRAINING loss= 0.6832 acc=57.07% VALIDATION loss= 0.6963 acc=52.46% ***\n",
      "\n",
      "Epoch  71 [   1/  59] loss= 0.6877 acc=55.47%\n",
      "Epoch  71 [   6/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  71 [  11/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  71 [  16/  59] loss= 0.6834 acc=57.03%\n",
      "Epoch  71 [  21/  59] loss= 0.6884 acc=55.47%\n",
      "Epoch  71 [  26/  59] loss= 0.6884 acc=55.47%\n",
      "Epoch  71 [  31/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  71 [  36/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  71 [  41/  59] loss= 0.6724 acc=60.94%\n",
      "Epoch  71 [  46/  59] loss= 0.6812 acc=57.81%\n",
      "Epoch  71 [  51/  59] loss= 0.6708 acc=61.72%\n",
      "Epoch  71 [  56/  59] loss= 0.6791 acc=58.59%\n",
      "*** Epoch  71 TRAINING loss= 0.6833 acc=57.06% VALIDATION loss= 0.6911 acc=54.10% ***\n",
      "\n",
      "Epoch  72 [   1/  59] loss= 0.6770 acc=59.38%\n",
      "Epoch  72 [   6/  59] loss= 0.7090 acc=47.66%\n",
      "Epoch  72 [  11/  59] loss= 0.6968 acc=52.34%\n",
      "Epoch  72 [  16/  59] loss= 0.6902 acc=54.69%\n",
      "Epoch  72 [  21/  59] loss= 0.6761 acc=59.38%\n",
      "Epoch  72 [  26/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  72 [  31/  59] loss= 0.6785 acc=58.59%\n",
      "Epoch  72 [  36/  59] loss= 0.6762 acc=59.38%\n",
      "Epoch  72 [  41/  59] loss= 0.6719 acc=60.94%\n",
      "Epoch  72 [  46/  59] loss= 0.6898 acc=54.69%\n",
      "Epoch  72 [  51/  59] loss= 0.6875 acc=55.47%\n",
      "Epoch  72 [  56/  59] loss= 0.6634 acc=64.84%\n",
      "*** Epoch  72 TRAINING loss= 0.6832 acc=57.10% VALIDATION loss= 0.7032 acc=49.18% ***\n",
      "\n",
      "Epoch  73 [   1/  59] loss= 0.6695 acc=62.50%\n",
      "Epoch  73 [   6/  59] loss= 0.6933 acc=53.12%\n",
      "Epoch  73 [  11/  59] loss= 0.6711 acc=61.72%\n",
      "Epoch  73 [  16/  59] loss= 0.6661 acc=63.28%\n",
      "Epoch  73 [  21/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch  73 [  26/  59] loss= 0.6740 acc=60.16%\n",
      "Epoch  73 [  31/  59] loss= 0.6762 acc=59.38%\n",
      "Epoch  73 [  36/  59] loss= 0.7064 acc=49.22%\n",
      "Epoch  73 [  41/  59] loss= 0.6720 acc=60.94%\n",
      "Epoch  73 [  46/  59] loss= 0.6448 acc=70.31%\n",
      "Epoch  73 [  51/  59] loss= 0.6608 acc=64.84%\n",
      "Epoch  73 [  56/  59] loss= 0.6988 acc=51.56%\n",
      "*** Epoch  73 TRAINING loss= 0.6831 acc=57.12% VALIDATION loss= 0.7143 acc=45.90% ***\n",
      "\n",
      "Epoch  74 [   1/  59] loss= 0.6789 acc=58.59%\n",
      "Epoch  74 [   6/  59] loss= 0.7072 acc=48.44%\n",
      "Epoch  74 [  11/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  74 [  16/  59] loss= 0.6788 acc=58.59%\n",
      "Epoch  74 [  21/  59] loss= 0.6766 acc=59.38%\n",
      "Epoch  74 [  26/  59] loss= 0.6877 acc=55.47%\n",
      "Epoch  74 [  31/  59] loss= 0.6741 acc=60.16%\n",
      "Epoch  74 [  36/  59] loss= 0.6670 acc=62.50%\n",
      "Epoch  74 [  41/  59] loss= 0.6738 acc=60.16%\n",
      "Epoch  74 [  46/  59] loss= 0.7113 acc=47.66%\n",
      "Epoch  74 [  51/  59] loss= 0.6680 acc=62.50%\n",
      "Epoch  74 [  56/  59] loss= 0.6750 acc=60.16%\n",
      "*** Epoch  74 TRAINING loss= 0.6834 acc=57.00% VALIDATION loss= 0.6740 acc=60.66% ***\n",
      "\n",
      "Epoch  75 [   1/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  75 [   6/  59] loss= 0.6873 acc=55.47%\n",
      "Epoch  75 [  11/  59] loss= 0.6773 acc=59.38%\n",
      "Epoch  75 [  16/  59] loss= 0.6976 acc=51.56%\n",
      "Epoch  75 [  21/  59] loss= 0.6771 acc=59.38%\n",
      "Epoch  75 [  26/  59] loss= 0.6640 acc=64.06%\n",
      "Epoch  75 [  31/  59] loss= 0.6878 acc=55.47%\n",
      "Epoch  75 [  36/  59] loss= 0.6973 acc=52.34%\n",
      "Epoch  75 [  41/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  75 [  46/  59] loss= 0.7028 acc=50.00%\n",
      "Epoch  75 [  51/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  75 [  56/  59] loss= 0.6854 acc=56.25%\n",
      "*** Epoch  75 TRAINING loss= 0.6836 acc=56.95% VALIDATION loss= 0.6544 acc=67.21% ***\n",
      "\n",
      "Epoch  76 [   1/  59] loss= 0.7120 acc=46.88%\n",
      "Epoch  76 [   6/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  76 [  11/  59] loss= 0.6814 acc=57.81%\n",
      "Epoch  76 [  16/  59] loss= 0.6758 acc=60.16%\n",
      "Epoch  76 [  21/  59] loss= 0.6928 acc=53.12%\n",
      "Epoch  76 [  26/  59] loss= 0.6707 acc=62.50%\n",
      "Epoch  76 [  31/  59] loss= 0.6775 acc=59.38%\n",
      "Epoch  76 [  36/  59] loss= 0.6941 acc=53.12%\n",
      "Epoch  76 [  41/  59] loss= 0.6624 acc=64.06%\n",
      "Epoch  76 [  46/  59] loss= 0.6881 acc=55.47%\n",
      "Epoch  76 [  51/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  76 [  56/  59] loss= 0.6531 acc=67.19%\n",
      "*** Epoch  76 TRAINING loss= 0.6834 acc=57.03% VALIDATION loss= 0.6822 acc=57.38% ***\n",
      "\n",
      "Epoch  77 [   1/  59] loss= 0.6997 acc=51.56%\n",
      "Epoch  77 [   6/  59] loss= 0.6645 acc=63.28%\n",
      "Epoch  77 [  11/  59] loss= 0.6785 acc=58.59%\n",
      "Epoch  77 [  16/  59] loss= 0.6690 acc=61.72%\n",
      "Epoch  77 [  21/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  77 [  26/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  77 [  31/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  77 [  36/  59] loss= 0.6878 acc=55.47%\n",
      "Epoch  77 [  41/  59] loss= 0.6746 acc=60.16%\n",
      "Epoch  77 [  46/  59] loss= 0.6769 acc=59.38%\n",
      "Epoch  77 [  51/  59] loss= 0.6586 acc=66.41%\n",
      "Epoch  77 [  56/  59] loss= 0.6854 acc=56.25%\n",
      "*** Epoch  77 TRAINING loss= 0.6832 acc=57.10% VALIDATION loss= 0.7051 acc=49.18% ***\n",
      "\n",
      "Epoch  78 [   1/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  78 [   6/  59] loss= 0.6744 acc=60.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  78 [  11/  59] loss= 0.6898 acc=54.69%\n",
      "Epoch  78 [  16/  59] loss= 0.6678 acc=62.50%\n",
      "Epoch  78 [  21/  59] loss= 0.6877 acc=55.47%\n",
      "Epoch  78 [  26/  59] loss= 0.6786 acc=58.59%\n",
      "Epoch  78 [  31/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  78 [  36/  59] loss= 0.6717 acc=60.94%\n",
      "Epoch  78 [  41/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  78 [  46/  59] loss= 0.7026 acc=50.78%\n",
      "Epoch  78 [  51/  59] loss= 0.6976 acc=52.34%\n",
      "Epoch  78 [  56/  59] loss= 0.7040 acc=50.00%\n",
      "*** Epoch  78 TRAINING loss= 0.6833 acc=57.04% VALIDATION loss= 0.6869 acc=55.74% ***\n",
      "\n",
      "Epoch  79 [   1/  59] loss= 0.6987 acc=51.56%\n",
      "Epoch  79 [   6/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  79 [  11/  59] loss= 0.6609 acc=65.62%\n",
      "Epoch  79 [  16/  59] loss= 0.6894 acc=54.69%\n",
      "Epoch  79 [  21/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  79 [  26/  59] loss= 0.6709 acc=61.72%\n",
      "Epoch  79 [  31/  59] loss= 0.6812 acc=57.81%\n",
      "Epoch  79 [  36/  59] loss= 0.6916 acc=53.91%\n",
      "Epoch  79 [  41/  59] loss= 0.6975 acc=51.56%\n",
      "Epoch  79 [  46/  59] loss= 0.6771 acc=59.38%\n",
      "Epoch  79 [  51/  59] loss= 0.6767 acc=59.38%\n",
      "Epoch  79 [  56/  59] loss= 0.6787 acc=58.59%\n",
      "*** Epoch  79 TRAINING loss= 0.6832 acc=57.07% VALIDATION loss= 0.6966 acc=52.46% ***\n",
      "\n",
      "Epoch  80 [   1/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  80 [   6/  59] loss= 0.6579 acc=65.62%\n",
      "Epoch  80 [  11/  59] loss= 0.6739 acc=60.16%\n",
      "Epoch  80 [  16/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  80 [  21/  59] loss= 0.6731 acc=60.16%\n",
      "Epoch  80 [  26/  59] loss= 0.7045 acc=50.78%\n",
      "Epoch  80 [  31/  59] loss= 0.6709 acc=60.94%\n",
      "Epoch  80 [  36/  59] loss= 0.6998 acc=51.56%\n",
      "Epoch  80 [  41/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  80 [  46/  59] loss= 0.6755 acc=60.16%\n",
      "Epoch  80 [  51/  59] loss= 0.6990 acc=50.78%\n",
      "Epoch  80 [  56/  59] loss= 0.6617 acc=65.62%\n",
      "*** Epoch  80 TRAINING loss= 0.6834 acc=57.08% VALIDATION loss= 0.6996 acc=50.82% ***\n",
      "\n",
      "Epoch  81 [   1/  59] loss= 0.6668 acc=63.28%\n",
      "Epoch  81 [   6/  59] loss= 0.6918 acc=53.91%\n",
      "Epoch  81 [  11/  59] loss= 0.6958 acc=52.34%\n",
      "Epoch  81 [  16/  59] loss= 0.6814 acc=57.81%\n",
      "Epoch  81 [  21/  59] loss= 0.6815 acc=57.81%\n",
      "Epoch  81 [  26/  59] loss= 0.7013 acc=50.00%\n",
      "Epoch  81 [  31/  59] loss= 0.6913 acc=53.91%\n",
      "Epoch  81 [  36/  59] loss= 0.6775 acc=59.38%\n",
      "Epoch  81 [  41/  59] loss= 0.6812 acc=57.81%\n",
      "Epoch  81 [  46/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  81 [  51/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  81 [  56/  59] loss= 0.6985 acc=52.34%\n",
      "*** Epoch  81 TRAINING loss= 0.6832 acc=57.10% VALIDATION loss= 0.7092 acc=49.18% ***\n",
      "\n",
      "Epoch  82 [   1/  59] loss= 0.7040 acc=50.78%\n",
      "Epoch  82 [   6/  59] loss= 0.7010 acc=51.56%\n",
      "Epoch  82 [  11/  59] loss= 0.6997 acc=51.56%\n",
      "Epoch  82 [  16/  59] loss= 0.6919 acc=53.91%\n",
      "Epoch  82 [  21/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  82 [  26/  59] loss= 0.6794 acc=58.59%\n",
      "Epoch  82 [  31/  59] loss= 0.6992 acc=50.78%\n",
      "Epoch  82 [  36/  59] loss= 0.6894 acc=54.69%\n",
      "Epoch  82 [  41/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  82 [  46/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  82 [  51/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  82 [  56/  59] loss= 0.6667 acc=62.50%\n",
      "*** Epoch  82 TRAINING loss= 0.6835 acc=57.02% VALIDATION loss= 0.6771 acc=59.02% ***\n",
      "\n",
      "Epoch  83 [   1/  59] loss= 0.6908 acc=54.69%\n",
      "Epoch  83 [   6/  59] loss= 0.6604 acc=64.06%\n",
      "Epoch  83 [  11/  59] loss= 0.6861 acc=56.25%\n",
      "Epoch  83 [  16/  59] loss= 0.6836 acc=57.03%\n",
      "Epoch  83 [  21/  59] loss= 0.7021 acc=51.56%\n",
      "Epoch  83 [  26/  59] loss= 0.7113 acc=48.44%\n",
      "Epoch  83 [  31/  59] loss= 0.6595 acc=64.84%\n",
      "Epoch  83 [  36/  59] loss= 0.6926 acc=53.91%\n",
      "Epoch  83 [  41/  59] loss= 0.6788 acc=58.59%\n",
      "Epoch  83 [  46/  59] loss= 0.6769 acc=59.38%\n",
      "Epoch  83 [  51/  59] loss= 0.7022 acc=50.00%\n",
      "Epoch  83 [  56/  59] loss= 0.6586 acc=66.41%\n",
      "*** Epoch  83 TRAINING loss= 0.6835 acc=57.00% VALIDATION loss= 0.6736 acc=60.66% ***\n",
      "\n",
      "Epoch  84 [   1/  59] loss= 0.6812 acc=57.81%\n",
      "Epoch  84 [   6/  59] loss= 0.6708 acc=61.72%\n",
      "Epoch  84 [  11/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  84 [  16/  59] loss= 0.6727 acc=60.94%\n",
      "Epoch  84 [  21/  59] loss= 0.6765 acc=59.38%\n",
      "Epoch  84 [  26/  59] loss= 0.6761 acc=59.38%\n",
      "Epoch  84 [  31/  59] loss= 0.6784 acc=58.59%\n",
      "Epoch  84 [  36/  59] loss= 0.6736 acc=60.16%\n",
      "Epoch  84 [  41/  59] loss= 0.6881 acc=55.47%\n",
      "Epoch  84 [  46/  59] loss= 0.6786 acc=58.59%\n",
      "Epoch  84 [  51/  59] loss= 0.6764 acc=59.38%\n",
      "Epoch  84 [  56/  59] loss= 0.6898 acc=54.69%\n",
      "*** Epoch  84 TRAINING loss= 0.6835 acc=56.99% VALIDATION loss= 0.6691 acc=62.30% ***\n",
      "\n",
      "Epoch  85 [   1/  59] loss= 0.7042 acc=49.22%\n",
      "Epoch  85 [   6/  59] loss= 0.6692 acc=62.50%\n",
      "Epoch  85 [  11/  59] loss= 0.6792 acc=58.59%\n",
      "Epoch  85 [  16/  59] loss= 0.6753 acc=60.16%\n",
      "Epoch  85 [  21/  59] loss= 0.6812 acc=57.81%\n",
      "Epoch  85 [  26/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  85 [  31/  59] loss= 0.7009 acc=50.78%\n",
      "Epoch  85 [  36/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  85 [  41/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  85 [  46/  59] loss= 0.6873 acc=55.47%\n",
      "Epoch  85 [  51/  59] loss= 0.6750 acc=60.16%\n",
      "Epoch  85 [  56/  59] loss= 0.6666 acc=63.28%\n",
      "*** Epoch  85 TRAINING loss= 0.6836 acc=56.95% VALIDATION loss= 0.6552 acc=67.21% ***\n",
      "\n",
      "Epoch  86 [   1/  59] loss= 0.6703 acc=61.72%\n",
      "Epoch  86 [   6/  59] loss= 0.6698 acc=61.72%\n",
      "Epoch  86 [  11/  59] loss= 0.6649 acc=63.28%\n",
      "Epoch  86 [  16/  59] loss= 0.6930 acc=53.91%\n",
      "Epoch  86 [  21/  59] loss= 0.6784 acc=58.59%\n",
      "Epoch  86 [  26/  59] loss= 0.6760 acc=59.38%\n",
      "Epoch  86 [  31/  59] loss= 0.6787 acc=58.59%\n",
      "Epoch  86 [  36/  59] loss= 0.6876 acc=55.47%\n",
      "Epoch  86 [  41/  59] loss= 0.6620 acc=64.84%\n",
      "Epoch  86 [  46/  59] loss= 0.6897 acc=54.69%\n",
      "Epoch  86 [  51/  59] loss= 0.6767 acc=59.38%\n",
      "Epoch  86 [  56/  59] loss= 0.6854 acc=56.25%\n",
      "*** Epoch  86 TRAINING loss= 0.6833 acc=57.07% VALIDATION loss= 0.6956 acc=52.46% ***\n",
      "\n",
      "Epoch  87 [   1/  59] loss= 0.6727 acc=60.94%\n",
      "Epoch  87 [   6/  59] loss= 0.7008 acc=50.78%\n",
      "Epoch  87 [  11/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  87 [  16/  59] loss= 0.6947 acc=53.12%\n",
      "Epoch  87 [  21/  59] loss= 0.6988 acc=51.56%\n",
      "Epoch  87 [  26/  59] loss= 0.6708 acc=61.72%\n",
      "Epoch  87 [  31/  59] loss= 0.6955 acc=52.34%\n",
      "Epoch  87 [  36/  59] loss= 0.6711 acc=61.72%\n",
      "Epoch  87 [  41/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  87 [  46/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  87 [  51/  59] loss= 0.6496 acc=69.53%\n",
      "Epoch  87 [  56/  59] loss= 0.6854 acc=56.25%\n",
      "*** Epoch  87 TRAINING loss= 0.6835 acc=56.98% VALIDATION loss= 0.6636 acc=63.93% ***\n",
      "\n",
      "Epoch  88 [   1/  59] loss= 0.6522 acc=67.97%\n",
      "Epoch  88 [   6/  59] loss= 0.7189 acc=45.31%\n",
      "Epoch  88 [  11/  59] loss= 0.7025 acc=50.78%\n",
      "Epoch  88 [  16/  59] loss= 0.6622 acc=64.06%\n",
      "Epoch  88 [  21/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  88 [  26/  59] loss= 0.6925 acc=53.91%\n",
      "Epoch  88 [  31/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  88 [  36/  59] loss= 0.6721 acc=60.94%\n",
      "Epoch  88 [  41/  59] loss= 0.7141 acc=46.09%\n",
      "Epoch  88 [  46/  59] loss= 0.6790 acc=58.59%\n",
      "Epoch  88 [  51/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  88 [  56/  59] loss= 0.6725 acc=60.94%\n",
      "*** Epoch  88 TRAINING loss= 0.6832 acc=57.06% VALIDATION loss= 0.6914 acc=54.10% ***\n",
      "\n",
      "Epoch  89 [   1/  59] loss= 0.6985 acc=51.56%\n",
      "Epoch  89 [   6/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  89 [  11/  59] loss= 0.6792 acc=58.59%\n",
      "Epoch  89 [  16/  59] loss= 0.6696 acc=62.50%\n",
      "Epoch  89 [  21/  59] loss= 0.6973 acc=51.56%\n",
      "Epoch  89 [  26/  59] loss= 0.6792 acc=58.59%\n",
      "Epoch  89 [  31/  59] loss= 0.6876 acc=55.47%\n",
      "Epoch  89 [  36/  59] loss= 0.6968 acc=52.34%\n",
      "Epoch  89 [  41/  59] loss= 0.7079 acc=48.44%\n",
      "Epoch  89 [  46/  59] loss= 0.6724 acc=60.94%\n",
      "Epoch  89 [  51/  59] loss= 0.6897 acc=54.69%\n",
      "Epoch  89 [  56/  59] loss= 0.6945 acc=53.12%\n",
      "*** Epoch  89 TRAINING loss= 0.6833 acc=57.06% VALIDATION loss= 0.6920 acc=54.10% ***\n",
      "\n",
      "Epoch  90 [   1/  59] loss= 0.6624 acc=64.06%\n",
      "Epoch  90 [   6/  59] loss= 0.6687 acc=61.72%\n",
      "Epoch  90 [  11/  59] loss= 0.6884 acc=55.47%\n",
      "Epoch  90 [  16/  59] loss= 0.6734 acc=60.16%\n",
      "Epoch  90 [  21/  59] loss= 0.7139 acc=47.66%\n",
      "Epoch  90 [  26/  59] loss= 0.6639 acc=63.28%\n",
      "Epoch  90 [  31/  59] loss= 0.6641 acc=63.28%\n",
      "Epoch  90 [  36/  59] loss= 0.7117 acc=47.66%\n",
      "Epoch  90 [  41/  59] loss= 0.6674 acc=62.50%\n",
      "Epoch  90 [  46/  59] loss= 0.6699 acc=61.72%\n",
      "Epoch  90 [  51/  59] loss= 0.6659 acc=63.28%\n",
      "Epoch  90 [  56/  59] loss= 0.6725 acc=60.94%\n",
      "*** Epoch  90 TRAINING loss= 0.6834 acc=56.99% VALIDATION loss= 0.6691 acc=62.30% ***\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  91 [   1/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  91 [   6/  59] loss= 0.7016 acc=50.00%\n",
      "Epoch  91 [  11/  59] loss= 0.6914 acc=53.91%\n",
      "Epoch  91 [  16/  59] loss= 0.6978 acc=51.56%\n",
      "Epoch  91 [  21/  59] loss= 0.7083 acc=47.66%\n",
      "Epoch  91 [  26/  59] loss= 0.6812 acc=57.81%\n",
      "Epoch  91 [  31/  59] loss= 0.6999 acc=50.78%\n",
      "Epoch  91 [  36/  59] loss= 0.6789 acc=58.59%\n",
      "Epoch  91 [  41/  59] loss= 0.6878 acc=55.47%\n",
      "Epoch  91 [  46/  59] loss= 0.6762 acc=59.38%\n",
      "Epoch  91 [  51/  59] loss= 0.6880 acc=55.47%\n",
      "Epoch  91 [  56/  59] loss= 0.6786 acc=58.59%\n",
      "*** Epoch  91 TRAINING loss= 0.6831 acc=57.12% VALIDATION loss= 0.7163 acc=45.90% ***\n",
      "\n",
      "Epoch  92 [   1/  59] loss= 0.6925 acc=53.91%\n",
      "Epoch  92 [   6/  59] loss= 0.6898 acc=54.69%\n",
      "Epoch  92 [  11/  59] loss= 0.6811 acc=57.81%\n",
      "Epoch  92 [  16/  59] loss= 0.6897 acc=54.69%\n",
      "Epoch  92 [  21/  59] loss= 0.6724 acc=60.94%\n",
      "Epoch  92 [  26/  59] loss= 0.6875 acc=55.47%\n",
      "Epoch  92 [  31/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  92 [  36/  59] loss= 0.7085 acc=47.66%\n",
      "Epoch  92 [  41/  59] loss= 0.6707 acc=61.72%\n",
      "Epoch  92 [  46/  59] loss= 0.6747 acc=60.16%\n",
      "Epoch  92 [  51/  59] loss= 0.6810 acc=57.81%\n",
      "Epoch  92 [  56/  59] loss= 0.7133 acc=46.88%\n",
      "*** Epoch  92 TRAINING loss= 0.6832 acc=57.08% VALIDATION loss= 0.7018 acc=50.82% ***\n",
      "\n",
      "Epoch  93 [   1/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  93 [   6/  59] loss= 0.6926 acc=53.91%\n",
      "Epoch  93 [  11/  59] loss= 0.6878 acc=55.47%\n",
      "Epoch  93 [  16/  59] loss= 0.6743 acc=60.16%\n",
      "Epoch  93 [  21/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  93 [  26/  59] loss= 0.6906 acc=54.69%\n",
      "Epoch  93 [  31/  59] loss= 0.6587 acc=64.84%\n",
      "Epoch  93 [  36/  59] loss= 0.6659 acc=62.50%\n",
      "Epoch  93 [  41/  59] loss= 0.6884 acc=55.47%\n",
      "Epoch  93 [  46/  59] loss= 0.6883 acc=55.47%\n",
      "Epoch  93 [  51/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  93 [  56/  59] loss= 0.6943 acc=53.12%\n",
      "*** Epoch  93 TRAINING loss= 0.6832 acc=57.10% VALIDATION loss= 0.7043 acc=49.18% ***\n",
      "\n",
      "Epoch  94 [   1/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  94 [   6/  59] loss= 0.6873 acc=55.47%\n",
      "Epoch  94 [  11/  59] loss= 0.6891 acc=54.69%\n",
      "Epoch  94 [  16/  59] loss= 0.6799 acc=58.59%\n",
      "Epoch  94 [  21/  59] loss= 0.6691 acc=63.28%\n",
      "Epoch  94 [  26/  59] loss= 0.6950 acc=52.34%\n",
      "Epoch  94 [  31/  59] loss= 0.6707 acc=61.72%\n",
      "Epoch  94 [  36/  59] loss= 0.6627 acc=64.06%\n",
      "Epoch  94 [  41/  59] loss= 0.6882 acc=55.47%\n",
      "Epoch  94 [  46/  59] loss= 0.6587 acc=64.84%\n",
      "Epoch  94 [  51/  59] loss= 0.6957 acc=53.12%\n",
      "Epoch  94 [  56/  59] loss= 0.6809 acc=57.81%\n",
      "*** Epoch  94 TRAINING loss= 0.6832 acc=57.12% VALIDATION loss= 0.7164 acc=45.90% ***\n",
      "\n",
      "Epoch  95 [   1/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  95 [   6/  59] loss= 0.6950 acc=53.12%\n",
      "Epoch  95 [  11/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  95 [  16/  59] loss= 0.6718 acc=60.94%\n",
      "Epoch  95 [  21/  59] loss= 0.6952 acc=53.12%\n",
      "Epoch  95 [  26/  59] loss= 0.6927 acc=53.91%\n",
      "Epoch  95 [  31/  59] loss= 0.6878 acc=55.47%\n",
      "Epoch  95 [  36/  59] loss= 0.7106 acc=47.66%\n",
      "Epoch  95 [  41/  59] loss= 0.6788 acc=58.59%\n",
      "Epoch  95 [  46/  59] loss= 0.6938 acc=53.12%\n",
      "Epoch  95 [  51/  59] loss= 0.6874 acc=55.47%\n",
      "Epoch  95 [  56/  59] loss= 0.6791 acc=58.59%\n",
      "*** Epoch  95 TRAINING loss= 0.6834 acc=56.98% VALIDATION loss= 0.6647 acc=63.93% ***\n",
      "\n",
      "Epoch  96 [   1/  59] loss= 0.6685 acc=62.50%\n",
      "Epoch  96 [   6/  59] loss= 0.6939 acc=53.12%\n",
      "Epoch  96 [  11/  59] loss= 0.6791 acc=58.59%\n",
      "Epoch  96 [  16/  59] loss= 0.6793 acc=58.59%\n",
      "Epoch  96 [  21/  59] loss= 0.7076 acc=47.66%\n",
      "Epoch  96 [  26/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  96 [  31/  59] loss= 0.6915 acc=53.91%\n",
      "Epoch  96 [  36/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  96 [  41/  59] loss= 0.6640 acc=64.06%\n",
      "Epoch  96 [  46/  59] loss= 0.6854 acc=56.25%\n",
      "Epoch  96 [  51/  59] loss= 0.6575 acc=65.62%\n",
      "Epoch  96 [  56/  59] loss= 0.7030 acc=50.78%\n",
      "*** Epoch  96 TRAINING loss= 0.6835 acc=56.98% VALIDATION loss= 0.6619 acc=63.93% ***\n",
      "\n",
      "Epoch  97 [   1/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  97 [   6/  59] loss= 0.6856 acc=56.25%\n",
      "Epoch  97 [  11/  59] loss= 0.6763 acc=59.38%\n",
      "Epoch  97 [  16/  59] loss= 0.6974 acc=52.34%\n",
      "Epoch  97 [  21/  59] loss= 0.6691 acc=61.72%\n",
      "Epoch  97 [  26/  59] loss= 0.6738 acc=60.16%\n",
      "Epoch  97 [  31/  59] loss= 0.6764 acc=59.38%\n",
      "Epoch  97 [  36/  59] loss= 0.6747 acc=60.16%\n",
      "Epoch  97 [  41/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  97 [  46/  59] loss= 0.6918 acc=53.91%\n",
      "Epoch  97 [  51/  59] loss= 0.6986 acc=51.56%\n",
      "Epoch  97 [  56/  59] loss= 0.6702 acc=61.72%\n",
      "*** Epoch  97 TRAINING loss= 0.6834 acc=56.99% VALIDATION loss= 0.6688 acc=62.30% ***\n",
      "\n",
      "Epoch  98 [   1/  59] loss= 0.6897 acc=54.69%\n",
      "Epoch  98 [   6/  59] loss= 0.6935 acc=53.12%\n",
      "Epoch  98 [  11/  59] loss= 0.6853 acc=56.25%\n",
      "Epoch  98 [  16/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch  98 [  21/  59] loss= 0.6579 acc=66.41%\n",
      "Epoch  98 [  26/  59] loss= 0.6497 acc=68.75%\n",
      "Epoch  98 [  31/  59] loss= 0.6857 acc=56.25%\n",
      "Epoch  98 [  36/  59] loss= 0.6884 acc=55.47%\n",
      "Epoch  98 [  41/  59] loss= 0.7117 acc=48.44%\n",
      "Epoch  98 [  46/  59] loss= 0.7009 acc=51.56%\n",
      "Epoch  98 [  51/  59] loss= 0.6787 acc=58.59%\n",
      "Epoch  98 [  56/  59] loss= 0.6768 acc=59.38%\n",
      "*** Epoch  98 TRAINING loss= 0.6836 acc=57.02% VALIDATION loss= 0.6780 acc=59.02% ***\n",
      "\n",
      "Epoch  99 [   1/  59] loss= 0.6895 acc=54.69%\n",
      "Epoch  99 [   6/  59] loss= 0.6565 acc=67.19%\n",
      "Epoch  99 [  11/  59] loss= 0.6574 acc=66.41%\n",
      "Epoch  99 [  16/  59] loss= 0.6786 acc=58.59%\n",
      "Epoch  99 [  21/  59] loss= 0.7054 acc=50.00%\n",
      "Epoch  99 [  26/  59] loss= 0.6809 acc=57.81%\n",
      "Epoch  99 [  31/  59] loss= 0.7114 acc=47.66%\n",
      "Epoch  99 [  36/  59] loss= 0.6832 acc=57.03%\n",
      "Epoch  99 [  41/  59] loss= 0.6720 acc=60.94%\n",
      "Epoch  99 [  46/  59] loss= 0.6744 acc=60.16%\n",
      "Epoch  99 [  51/  59] loss= 0.7080 acc=48.44%\n",
      "Epoch  99 [  56/  59] loss= 0.6943 acc=53.12%\n",
      "*** Epoch  99 TRAINING loss= 0.6833 acc=57.07% VALIDATION loss= 0.6958 acc=52.46% ***\n",
      "\n",
      "Epoch 100 [   1/  59] loss= 0.7025 acc=50.00%\n",
      "Epoch 100 [   6/  59] loss= 0.6833 acc=57.03%\n",
      "Epoch 100 [  11/  59] loss= 0.6872 acc=55.47%\n",
      "Epoch 100 [  16/  59] loss= 0.6835 acc=57.03%\n",
      "Epoch 100 [  21/  59] loss= 0.6798 acc=58.59%\n",
      "Epoch 100 [  26/  59] loss= 0.6646 acc=64.84%\n",
      "Epoch 100 [  31/  59] loss= 0.6913 acc=53.91%\n",
      "Epoch 100 [  36/  59] loss= 0.6916 acc=53.91%\n",
      "Epoch 100 [  41/  59] loss= 0.6896 acc=54.69%\n",
      "Epoch 100 [  46/  59] loss= 0.6987 acc=51.56%\n",
      "Epoch 100 [  51/  59] loss= 0.6855 acc=56.25%\n",
      "Epoch 100 [  56/  59] loss= 0.6976 acc=52.34%\n",
      "*** Epoch 100 TRAINING loss= 0.6832 acc=57.07% VALIDATION loss= 0.6974 acc=52.46% ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    for iteration in range(iterations):\n",
    "        train_features, train_labels = dataset_iterator.get_next()\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = loss_fn(model, train_features, train_labels, True)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        train_loss += loss\n",
    "        \n",
    "        acc = accuracy_fn(model, train_features, train_labels, False)\n",
    "        train_acc += acc\n",
    "        \n",
    "        if iteration % 5 == 0:\n",
    "            print('Epoch {:3d} [{:4d}/{:4d}] loss={:7.4f} acc={:.2%}'.format(epoch + 1, iteration + 1, iterations, loss, acc))\n",
    "    \n",
    "    train_loss /= iterations\n",
    "    train_acc /= iterations\n",
    "    \n",
    "    val_features, val_labels = dataset_iterator.get_next()\n",
    "    val_loss = loss_fn(model, val_features, val_labels, False)\n",
    "    val_acc = accuracy_fn(model, val_features, val_labels, False)\n",
    "\n",
    "    print('*** Epoch {:3d} TRAINING loss={:7.4f} acc={:.2%} VALIDATION loss={:7.4f} acc={:.2%} ***\\n'.format(epoch + 1, train_loss, train_acc, val_loss, val_acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 57.03%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_fn(model, x_train, y_train, False)\n",
    "print('Accuracy : {:.2%}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
